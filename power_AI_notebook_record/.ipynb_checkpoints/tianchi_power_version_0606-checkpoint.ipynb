{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  user_id  power_consumption\n",
       "0  2015-01-01        1               1135\n",
       "1  2015-01-02        1                570\n",
       "2  2015-01-03        1               3418\n",
       "3  2015-01-04        1               3968\n",
       "4  2015-01-05        1               3986"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tianchi_power.csv\")\n",
    "df['record_date'] = pd.to_datetime(df['record_date'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充缺省值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>record_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id record_date\n",
       "0        1  2015-01-01\n",
       "1        1  2015-01-02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range(\"2015-01-01\",\"2016-08-31\", freq=\"1D\")\n",
    "userid = pd.DataFrame({'user_id':df['user_id'].unique()})\n",
    "dates = pd.DataFrame(dates)\n",
    "dates.columns = ['record_date']\n",
    "userid['key'] = 0\n",
    "dates['key'] = 0\n",
    "full = userid.merge(dates, how='left', on = 'key')\n",
    "full.drop('key',1, inplace=True)\n",
    "full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885486, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(full, df, how='left', on=['user_id','record_date'])\n",
    "df['power_consumption'] = df['power_consumption'].interpolate()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['dow'] = df['record_date'].apply(lambda x: x.dayofweek)\n",
    "df['doy'] = df['record_date'].apply(lambda x: x.dayofyear)\n",
    "df['day'] = df['record_date'].apply(lambda x: x.day)\n",
    "df['month'] = df['record_date'].apply(lambda x: x.month)\n",
    "df['year'] = df['record_date'].apply(lambda x: x.year)\n",
    "\n",
    "def map_season(month):\n",
    "    month_dic = {1:1, 2:1, 3:2, 4:2, 5:3, 6:3, 7:3, 8:3, 9:3, 10:4, 11:4, 12:1}\n",
    "    return month_dic[month]\n",
    "\n",
    "df['season'] = df['month'].apply(lambda x: map_season(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 用电量聚合到一个月\n",
    "\n",
    "base_df = df[['record_date','power_consumption']].groupby(by='record_date').agg('sum')\n",
    "base_df = base_df.reset_index()\n",
    "base_df.head()\n",
    "base_df.shape\n",
    "# df = base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拼接测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>4627029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>4618467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>4490739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>4367727.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>4253298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    record_date  power_consumption\n",
       "578  2016-09-01          4627029.0\n",
       "579  2016-09-02          4618467.0\n",
       "580  2016-09-03          4490739.0\n",
       "581  2016-09-04          4367727.0\n",
       "582  2016-09-05          4253298.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = base_df[(base_df.record_date>='2016-08-01')&(base_df.record_date<='2016-08-30')]\n",
    "df_test['record_date'] = pd.DataFrame(df_test['record_date']+pd.Timedelta('31 days'))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2900575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3158211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3596487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>3939672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4101790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  power_consumption\n",
       "0  2015-01-01          2900575.0\n",
       "1  2015-01-02          3158211.0\n",
       "2  2015-01-03          3596487.0\n",
       "3  2015-01-04          3939672.0\n",
       "4  2015-01-05          4101790.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([base_df, df_test]).sort_values(['record_date'])\n",
    "# base_df.shape\n",
    "\n",
    "# df = base_df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2900575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3158211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3596487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>3939672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4101790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  power_consumption\n",
       "0  2015-01-01          2900575.0\n",
       "1  2015-01-02          3158211.0\n",
       "2  2015-01-03          3596487.0\n",
       "3  2015-01-04          3939672.0\n",
       "4  2015-01-05          4101790.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_df['dow'] = base_df['record_date'].apply(lambda x: x.dayofweek)\n",
    "base_df['doy'] = base_df['record_date'].apply(lambda x: x.dayofyear)\n",
    "base_df['day'] = base_df['record_date'].apply(lambda x: x.day)\n",
    "base_df['month'] = base_df['record_date'].apply(lambda x: x.month)\n",
    "base_df['year'] = base_df['record_date'].apply(lambda x: x.year)\n",
    "\n",
    "def map_season(month):\n",
    "    month_dic = {1:1, 2:1, 3:2, 4:2, 5:3, 6:3, 7:3, 8:3, 9:3, 10:4, 11:4, 12:1}\n",
    "    return month_dic[month]\n",
    "\n",
    "# base_df['season'] = base_df['month'].apply(lambda x: map_season(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加更多特征\n",
    "### 先添加前一个月的均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3.961383e+06</td>\n",
       "      <td>303629.486622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>3.478852e+06</td>\n",
       "      <td>564753.747993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>3.768333e+06</td>\n",
       "      <td>190787.832757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month          mean            std\n",
       "0  2015      1           NaN            NaN\n",
       "1  2015      2  3.961383e+06  303629.486622\n",
       "2  2015      3  2.795163e+06  769697.864999\n",
       "3  2015      4  3.478852e+06  564753.747993\n",
       "4  2015      5  3.768333e+06  190787.832757"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = base_df[['power_consumption','year','month']].groupby(by=['year', 'month']).agg(['mean', 'std'])\n",
    "df_stats.head()\n",
    "\n",
    "df_stats.columns = df_stats.columns.droplevel(0)\n",
    "df_stats = df_stats.reset_index()\n",
    "df_stats.head()\n",
    "df_stats['mean'] = df_stats['mean'].shift(1)\n",
    "# df_stats['2_m_mean'] = df_stats['mean'].shift(2)\n",
    "df_stats['std'] = df_stats['std'].shift(1)\n",
    "# df_stats['2_m_std'] = df_stats['std'].shift(2)\n",
    "df_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2900575.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3158211.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3596487.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>3939672.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4101790.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  power_consumption  dow  doy  day  month  year  mean  std\n",
       "0  2015-01-01          2900575.0    3    1    1      1  2015   NaN  NaN\n",
       "1  2015-01-02          3158211.0    4    2    2      1  2015   NaN  NaN\n",
       "2  2015-01-03          3596487.0    5    3    3      1  2015   NaN  NaN\n",
       "3  2015-01-04          3939672.0    6    4    4      1  2015   NaN  NaN\n",
       "4  2015-01-05          4101790.0    0    5    5      1  2015   NaN  NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.merge('base_df','df_stats',on=['year','month'])\n",
    "train = pd.merge(base_df, df_stats, how='left', on=['year','month'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把一个月分成上下 半月\n",
    "### 用它们的均值之差表示数据上下起伏趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>first_half</th>\n",
       "      <th>second_half</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>156902.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>1219955.3282051282</td>\n",
       "      <td>230498.6958333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>164766.2708333335</td>\n",
       "      <td>26365.933333333116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month          first_half         second_half\n",
       "0  2015      1                 NaN                 NaN\n",
       "1  2015      2                 nan         156902.8125\n",
       "2  2015      3  -674272.1458333335  -1223101.628205128\n",
       "3  2015      4  1219955.3282051282   230498.6958333333\n",
       "4  2015      5   164766.2708333335  26365.933333333116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先对一个月做切分\n",
    "def month_half(day):\n",
    "    if day>=1 and day<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "base_df['month_half'] = base_df['day'].apply(lambda x:month_half(x))\n",
    "# base_df['week_period'] = base_df['day'].apply(lambda x:week_period(x))\n",
    "\n",
    "half = base_df[['power_consumption','year','month','month_half']].groupby(by=['year', 'month', 'month_half']).agg('mean')\n",
    "half = half.reset_index()\n",
    "half.head()\n",
    "\n",
    "half['month_half'] = half['power_consumption'].diff(1)\n",
    "month_period_df = half.drop('power_consumption',1)\n",
    "# half.head()\n",
    "\n",
    "month_period_df = month_period_df[['year','month','month_half']].groupby(by=['year','month']).agg(lambda x: \",\".join(x.apply(str).values.tolist()))\n",
    "month_period_df = month_period_df.reset_index()\n",
    "month_period_df[['first_half','second_half']] =  month_period_df['month_half'].str.split(',', expand=True) \n",
    "month_period_df = month_period_df.drop('month_half',1)\n",
    "\n",
    "# month_1_columns = [tmp+'_1month' for tmp in ['month_period_1', 'month_period_2','month_period_3']]\n",
    "month_period_df[['first_half','second_half']] = month_period_df[['first_half','second_half']].shift(1)\n",
    "# month_2_columns = [tmp+'_2month' for tmp in ['month_period_1', 'month_period_2','month_period_3']]\n",
    "# month_period_df[month_2_columns] = month_period_df[['month_period_1', 'month_period_2','month_period_3']].shift(2)\n",
    "\n",
    "month_period_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>first_half</th>\n",
       "      <th>second_half</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2900575.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3158211.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3596487.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>3939672.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4101790.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  power_consumption  dow  doy  day  month  year  mean  std  \\\n",
       "0  2015-01-01          2900575.0    3    1    1      1  2015   NaN  NaN   \n",
       "1  2015-01-02          3158211.0    4    2    2      1  2015   NaN  NaN   \n",
       "2  2015-01-03          3596487.0    5    3    3      1  2015   NaN  NaN   \n",
       "3  2015-01-04          3939672.0    6    4    4      1  2015   NaN  NaN   \n",
       "4  2015-01-05          4101790.0    0    5    5      1  2015   NaN  NaN   \n",
       "\n",
       "  first_half second_half  \n",
       "0        NaN         NaN  \n",
       "1        NaN         NaN  \n",
       "2        NaN         NaN  \n",
       "3        NaN         NaN  \n",
       "4        NaN         NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 合并\n",
    "train =  pd.merge(train, month_period_df, how='left', on=['year','month'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把一个月分成上中下旬3个month_periods 或者 4周总共4个week_periods\n",
    "### 用它们的均值之差表示数据上下起伏趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先对一个月做切分\n",
    "def month_period(day):\n",
    "    if day>=1 and day<=10:\n",
    "        return 1\n",
    "    elif day>=11 and day<=20:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def week_period(day):\n",
    "    if day>=1 and day<=7:\n",
    "        return 1\n",
    "    elif day>=8 and day<=14:\n",
    "        return 2\n",
    "    elif day>=15 and day<=21:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "base_df['month_period'] = base_df['day'].apply(lambda x:month_period(x))\n",
    "base_df['week_period'] = base_df['day'].apply(lambda x:week_period(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照period求均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>month_period</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.825766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.016926e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.034177e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.691394e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.338909e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  month_period  power_consumption\n",
       "0  2015      1             1       3.825766e+06\n",
       "1  2015      1             2       4.016926e+06\n",
       "2  2015      1             3       4.034177e+06\n",
       "3  2015      2             1       3.691394e+06\n",
       "4  2015      2             2       2.338909e+06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_period_df = base_df[['power_consumption','year','month','month_period']].groupby(by=['year', 'month', 'month_period']).agg('mean')\n",
    "month_period_df = month_period_df.reset_index()\n",
    "month_period_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求出来均值之差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_period_df['month_period'] = month_period_df['power_consumption'].diff(1)\n",
    "month_period_df['3sepmean'] = month_period_df['power_consumption']#.diff(1)\n",
    "month_period_df = month_period_df.drop('power_consumption',1)\n",
    "month_period_df.head()\n",
    "\n",
    "mdf = month_period_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充上个月和上上个月的趋势数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>3sepmean_1</th>\n",
       "      <th>3sepmean_2</th>\n",
       "      <th>3sepmean_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3825766.2</td>\n",
       "      <td>4016926.2</td>\n",
       "      <td>4034177.4545454546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>3691394.3</td>\n",
       "      <td>2338908.6</td>\n",
       "      <td>2245192.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>3108414.7</td>\n",
       "      <td>3667572.75</td>\n",
       "      <td>3644050.090909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>3753272.1</td>\n",
       "      <td>3727802.35</td>\n",
       "      <td>3823925.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month 3sepmean_1  3sepmean_2          3sepmean_3\n",
       "0  2015      1        NaN         NaN                 NaN\n",
       "1  2015      2  3825766.2   4016926.2  4034177.4545454546\n",
       "2  2015      3  3691394.3   2338908.6        2245192.0625\n",
       "3  2015      4  3108414.7  3667572.75   3644050.090909091\n",
       "4  2015      5  3753272.1  3727802.35          3823925.45"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_period_df = month_period_df[['year','month','month_period']].groupby(by=['year','month']).agg(lambda x: \",\".join(x.apply(str).values.tolist()))\n",
    "month_period_df = month_period_df.reset_index()\n",
    "month_period_df[['month_period_1','month_period_2','month_period_3']] =  month_period_df['month_period'].str.split(',', expand=True) \n",
    "month_period_df = month_period_df.drop('month_period',1)\n",
    "\n",
    "# month_1_columns = [tmp+'_1month' for tmp in ['month_period_1', 'month_period_2','month_period_3']]\n",
    "month_period_df[['month_period_1', 'month_period_2','month_period_3']] = month_period_df[['month_period_1', 'month_period_2','month_period_3']].shift(1)\n",
    "\n",
    "\n",
    "# 添加每一旬的均值做为特征\n",
    "mdf = mdf[['year','month','3sepmean']].groupby(by=['year','month']).agg(lambda x: \",\".join(x.apply(str).values.tolist()))\n",
    "mdf = mdf.reset_index()\n",
    "mdf[['3sepmean_1','3sepmean_2','3sepmean_3']] =  mdf['3sepmean'].str.split(',', expand=True) \n",
    "mdf = mdf.drop('3sepmean',1)\n",
    "\n",
    "# month_1_columns = [tmp+'_1month' for tmp in ['month_period_1', 'month_period_2','month_period_3']]\n",
    "mdf[['3sepmean_1','3sepmean_2','3sepmean_3']] = mdf[['3sepmean_1','3sepmean_2','3sepmean_3']].shift(1)\n",
    "# month_2_columns = [tmp+'_2month' for tmp in ['month_period_1', 'month_period_2','month_period_3']]\n",
    "# month_period_df[month_2_columns] = month_period_df[['month_period_1', 'month_period_2','month_period_3']].shift(2)\n",
    "\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>first_half</th>\n",
       "      <th>second_half</th>\n",
       "      <th>month_period_1</th>\n",
       "      <th>month_period_2</th>\n",
       "      <th>month_period_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2900575.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>3158211.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3596487.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>3939672.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>4101790.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_date  power_consumption  dow  doy  day  month  year  mean  std  \\\n",
       "0  2015-01-01          2900575.0    3    1    1      1  2015   NaN  NaN   \n",
       "1  2015-01-02          3158211.0    4    2    2      1  2015   NaN  NaN   \n",
       "2  2015-01-03          3596487.0    5    3    3      1  2015   NaN  NaN   \n",
       "3  2015-01-04          3939672.0    6    4    4      1  2015   NaN  NaN   \n",
       "4  2015-01-05          4101790.0    0    5    5      1  2015   NaN  NaN   \n",
       "\n",
       "  first_half second_half month_period_1 month_period_2 month_period_3  \n",
       "0        NaN         NaN            NaN            NaN            NaN  \n",
       "1        NaN         NaN            NaN            NaN            NaN  \n",
       "2        NaN         NaN            NaN            NaN            NaN  \n",
       "3        NaN         NaN            NaN            NaN            NaN  \n",
       "4        NaN         NaN            NaN            NaN            NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并\n",
    "train_mon =  pd.merge(train, month_period_df, how='left', on=['year','month'])\n",
    "train_mon.head()\n",
    "\n",
    "# train_mon =  pd.merge(train_mon, mdf, how='left', on=['year','month'])\n",
    "# train_mon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "week_period_df = base_df[['power_consumption','year','month','week_period']].groupby(by=['year', 'month', 'week_period']).agg('mean')\n",
    "week_period_df = week_period_df.reset_index()\n",
    "# week_period_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "week_period_df['week_period'] = week_period_df['power_consumption'].diff(1)\n",
    "week_period_df = week_period_df.drop('power_consumption',1)\n",
    "# week_period_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_period_1</th>\n",
       "      <th>week_period_2</th>\n",
       "      <th>week_period_3</th>\n",
       "      <th>week_period_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>297703.42857142864</td>\n",
       "      <td>46736.28571428545</td>\n",
       "      <td>-31404.27142857155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>645923.0714285714</td>\n",
       "      <td>821015.2142857141</td>\n",
       "      <td>-292440.07142857136</td>\n",
       "      <td>245783.85714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>-9620.857142857276</td>\n",
       "      <td>113845.42857142864</td>\n",
       "      <td>-66743.64285714272</td>\n",
       "      <td>91990.90476190485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month       week_period_1       week_period_2        week_period_3  \\\n",
       "0  2015      1                 NaN                 NaN                  NaN   \n",
       "1  2015      2                 nan  297703.42857142864    46736.28571428545   \n",
       "2  2015      3  -220744.0142857139  -739169.8571428573  -1042483.8571428573   \n",
       "3  2015      4   645923.0714285714   821015.2142857141  -292440.07142857136   \n",
       "4  2015      5  -9620.857142857276  113845.42857142864   -66743.64285714272   \n",
       "\n",
       "        week_period_4  \n",
       "0                 NaN  \n",
       "1  -31404.27142857155  \n",
       "2  252348.35714285728  \n",
       "3  245783.85714285728  \n",
       "4   91990.90476190485  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将每个月中四个周的值分为四列。\n",
    "week_period_df = week_period_df[['year','month','week_period']].groupby(by=['year','month']).agg(lambda x: \",\".join(x.apply(str).values.tolist()))\n",
    "week_period_df = week_period_df.reset_index()\n",
    "week_period_df[['week_period_1','week_period_2','week_period_3','week_period_4']] =  week_period_df['week_period'].str.split(',', expand=True) \n",
    "week_period_df = week_period_df.drop('week_period',1)\n",
    "\n",
    "add_columns_1 = [tmp+'_1month' for tmp in ['week_period_1', 'week_period_2','week_period_3', 'week_period_4']]\n",
    "week_period_df[['week_period_1','week_period_2','week_period_3','week_period_4']] = week_period_df[['week_period_1', 'week_period_2','week_period_3', 'week_period_4']].shift(1)\n",
    "# add_columns_2 = [tmp+'_2month' for tmp in ['week_period_1', 'week_period_2','week_period_3', 'week_period_4']]\n",
    "# week_period_df[add_columns_2] = week_period_df[['week_period_1', 'week_period_2','week_period_3', 'week_period_4']].shift(2)\n",
    "\n",
    "week_period_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加 week period 相关特征\n",
    "df_final = pd.merge(train_mon, week_period_df, how='left', on=['year','month']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_date', 'power_consumption', 'dow', 'doy', 'day', 'month',\n",
       "       'year', 'mean', 'std', 'first_half', 'second_half', 'month_period_1',\n",
       "       'month_period_2', 'month_period_3', 'week_period_1', 'week_period_2',\n",
       "       'week_period_3', 'week_period_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉不需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_date</th>\n",
       "      <th>power_consumption</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>first_half</th>\n",
       "      <th>second_half</th>\n",
       "      <th>month_period_1</th>\n",
       "      <th>month_period_2</th>\n",
       "      <th>month_period_3</th>\n",
       "      <th>week_period_1</th>\n",
       "      <th>week_period_2</th>\n",
       "      <th>week_period_3</th>\n",
       "      <th>week_period_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>2900464.0</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "      <td>-342783.1545454548</td>\n",
       "      <td>-1352485.6999999997</td>\n",
       "      <td>-93716.5375000001</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>3334082.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "      <td>-342783.1545454548</td>\n",
       "      <td>-1352485.6999999997</td>\n",
       "      <td>-93716.5375000001</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>3492606.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "      <td>-342783.1545454548</td>\n",
       "      <td>-1352485.6999999997</td>\n",
       "      <td>-93716.5375000001</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>3597890.0</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "      <td>-342783.1545454548</td>\n",
       "      <td>-1352485.6999999997</td>\n",
       "      <td>-93716.5375000001</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>1798044.0</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.1458333335</td>\n",
       "      <td>-1223101.628205128</td>\n",
       "      <td>-342783.1545454548</td>\n",
       "      <td>-1352485.6999999997</td>\n",
       "      <td>-93716.5375000001</td>\n",
       "      <td>-220744.0142857139</td>\n",
       "      <td>-739169.8571428573</td>\n",
       "      <td>-1042483.8571428573</td>\n",
       "      <td>252348.35714285728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_date  power_consumption  dow  doy  day  month  year          mean  \\\n",
       "59  2015-03-01          2900464.0    6   60    1      3  2015  2.795163e+06   \n",
       "60  2015-03-02          3334082.0    0   61    2      3  2015  2.795163e+06   \n",
       "61  2015-03-03          3492606.0    1   62    3      3  2015  2.795163e+06   \n",
       "62  2015-03-04          3597890.0    2   63    4      3  2015  2.795163e+06   \n",
       "63  2015-03-05          1798044.0    3   64    5      3  2015  2.795163e+06   \n",
       "\n",
       "              std          first_half         second_half      month_period_1  \\\n",
       "59  769697.864999  -674272.1458333335  -1223101.628205128  -342783.1545454548   \n",
       "60  769697.864999  -674272.1458333335  -1223101.628205128  -342783.1545454548   \n",
       "61  769697.864999  -674272.1458333335  -1223101.628205128  -342783.1545454548   \n",
       "62  769697.864999  -674272.1458333335  -1223101.628205128  -342783.1545454548   \n",
       "63  769697.864999  -674272.1458333335  -1223101.628205128  -342783.1545454548   \n",
       "\n",
       "         month_period_2     month_period_3       week_period_1  \\\n",
       "59  -1352485.6999999997  -93716.5375000001  -220744.0142857139   \n",
       "60  -1352485.6999999997  -93716.5375000001  -220744.0142857139   \n",
       "61  -1352485.6999999997  -93716.5375000001  -220744.0142857139   \n",
       "62  -1352485.6999999997  -93716.5375000001  -220744.0142857139   \n",
       "63  -1352485.6999999997  -93716.5375000001  -220744.0142857139   \n",
       "\n",
       "         week_period_2        week_period_3       week_period_4  \n",
       "59  -739169.8571428573  -1042483.8571428573  252348.35714285728  \n",
       "60  -739169.8571428573  -1042483.8571428573  252348.35714285728  \n",
       "61  -739169.8571428573  -1042483.8571428573  252348.35714285728  \n",
       "62  -739169.8571428573  -1042483.8571428573  252348.35714285728  \n",
       "63  -739169.8571428573  -1042483.8571428573  252348.35714285728  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_final[df_final.record_date>='2015-03-01']\n",
    "# df_final['previous_2months_diff'] = df_final['1_m_mean']-df_final['2_m_mean']\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df1 = df_final[(df_final.record_date >= '2016-03-01')]#\n",
    "# df2 = df_final[(df_final.record_date < '2016-01-01')]#\n",
    "# # df_final = df_final[(df_final.record_date >= '2016-03-01')]#| (df_final.record_date < '2016-01-01')]\n",
    "# # df_final['previous_2months_diff'] = df_final['1_m_mean']-df_final['2_m_mean']\n",
    "# df_final = pd.concat([df2,df1])\n",
    "# df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-03-01T00:00:00.000000000', '2015-03-02T00:00:00.000000000',\n",
       "       '2015-03-03T00:00:00.000000000', '2015-03-04T00:00:00.000000000',\n",
       "       '2015-03-05T00:00:00.000000000', '2015-03-06T00:00:00.000000000',\n",
       "       '2015-03-07T00:00:00.000000000', '2015-03-08T00:00:00.000000000',\n",
       "       '2015-03-09T00:00:00.000000000', '2015-03-10T00:00:00.000000000',\n",
       "       '2015-03-11T00:00:00.000000000', '2015-03-12T00:00:00.000000000',\n",
       "       '2015-03-13T00:00:00.000000000', '2015-03-14T00:00:00.000000000',\n",
       "       '2015-03-15T00:00:00.000000000', '2015-03-16T00:00:00.000000000',\n",
       "       '2015-03-17T00:00:00.000000000', '2015-03-18T00:00:00.000000000',\n",
       "       '2015-03-19T00:00:00.000000000', '2015-03-20T00:00:00.000000000',\n",
       "       '2015-03-21T00:00:00.000000000', '2015-03-22T00:00:00.000000000',\n",
       "       '2015-03-23T00:00:00.000000000', '2015-03-24T00:00:00.000000000',\n",
       "       '2015-03-25T00:00:00.000000000', '2015-03-26T00:00:00.000000000',\n",
       "       '2015-03-27T00:00:00.000000000', '2015-03-28T00:00:00.000000000',\n",
       "       '2015-03-29T00:00:00.000000000', '2015-03-30T00:00:00.000000000',\n",
       "       '2015-03-31T00:00:00.000000000', '2015-04-01T00:00:00.000000000',\n",
       "       '2015-04-02T00:00:00.000000000', '2015-04-03T00:00:00.000000000',\n",
       "       '2015-04-04T00:00:00.000000000', '2015-04-05T00:00:00.000000000',\n",
       "       '2015-04-06T00:00:00.000000000', '2015-04-07T00:00:00.000000000',\n",
       "       '2015-04-08T00:00:00.000000000', '2015-04-09T00:00:00.000000000',\n",
       "       '2015-04-10T00:00:00.000000000', '2015-04-11T00:00:00.000000000',\n",
       "       '2015-04-12T00:00:00.000000000', '2015-04-13T00:00:00.000000000',\n",
       "       '2015-04-14T00:00:00.000000000', '2015-04-15T00:00:00.000000000',\n",
       "       '2015-04-16T00:00:00.000000000', '2015-04-17T00:00:00.000000000',\n",
       "       '2015-04-18T00:00:00.000000000', '2015-04-19T00:00:00.000000000',\n",
       "       '2015-04-20T00:00:00.000000000', '2015-04-21T00:00:00.000000000',\n",
       "       '2015-04-22T00:00:00.000000000', '2015-04-23T00:00:00.000000000',\n",
       "       '2015-04-24T00:00:00.000000000', '2015-04-25T00:00:00.000000000',\n",
       "       '2015-04-26T00:00:00.000000000', '2015-04-27T00:00:00.000000000',\n",
       "       '2015-04-28T00:00:00.000000000', '2015-04-29T00:00:00.000000000',\n",
       "       '2015-04-30T00:00:00.000000000', '2015-05-01T00:00:00.000000000',\n",
       "       '2015-05-02T00:00:00.000000000', '2015-05-03T00:00:00.000000000',\n",
       "       '2015-05-04T00:00:00.000000000', '2015-05-05T00:00:00.000000000',\n",
       "       '2015-05-06T00:00:00.000000000', '2015-05-07T00:00:00.000000000',\n",
       "       '2015-05-08T00:00:00.000000000', '2015-05-09T00:00:00.000000000',\n",
       "       '2015-05-10T00:00:00.000000000', '2015-05-11T00:00:00.000000000',\n",
       "       '2015-05-12T00:00:00.000000000', '2015-05-13T00:00:00.000000000',\n",
       "       '2015-05-14T00:00:00.000000000', '2015-05-15T00:00:00.000000000',\n",
       "       '2015-05-16T00:00:00.000000000', '2015-05-17T00:00:00.000000000',\n",
       "       '2015-05-18T00:00:00.000000000', '2015-05-19T00:00:00.000000000',\n",
       "       '2015-05-20T00:00:00.000000000', '2015-05-21T00:00:00.000000000',\n",
       "       '2015-05-22T00:00:00.000000000', '2015-05-23T00:00:00.000000000',\n",
       "       '2015-05-24T00:00:00.000000000', '2015-05-25T00:00:00.000000000',\n",
       "       '2015-05-26T00:00:00.000000000', '2015-05-27T00:00:00.000000000',\n",
       "       '2015-05-28T00:00:00.000000000', '2015-05-29T00:00:00.000000000',\n",
       "       '2015-05-30T00:00:00.000000000', '2015-05-31T00:00:00.000000000',\n",
       "       '2015-06-01T00:00:00.000000000', '2015-06-02T00:00:00.000000000',\n",
       "       '2015-06-03T00:00:00.000000000', '2015-06-04T00:00:00.000000000',\n",
       "       '2015-06-05T00:00:00.000000000', '2015-06-06T00:00:00.000000000',\n",
       "       '2015-06-07T00:00:00.000000000', '2015-06-08T00:00:00.000000000',\n",
       "       '2015-06-09T00:00:00.000000000', '2015-06-10T00:00:00.000000000',\n",
       "       '2015-06-11T00:00:00.000000000', '2015-06-12T00:00:00.000000000',\n",
       "       '2015-06-13T00:00:00.000000000', '2015-06-14T00:00:00.000000000',\n",
       "       '2015-06-15T00:00:00.000000000', '2015-06-16T00:00:00.000000000',\n",
       "       '2015-06-17T00:00:00.000000000', '2015-06-18T00:00:00.000000000',\n",
       "       '2015-06-19T00:00:00.000000000', '2015-06-20T00:00:00.000000000',\n",
       "       '2015-06-21T00:00:00.000000000', '2015-06-22T00:00:00.000000000',\n",
       "       '2015-06-23T00:00:00.000000000', '2015-06-24T00:00:00.000000000',\n",
       "       '2015-06-25T00:00:00.000000000', '2015-06-26T00:00:00.000000000',\n",
       "       '2015-06-27T00:00:00.000000000', '2015-06-28T00:00:00.000000000',\n",
       "       '2015-06-29T00:00:00.000000000', '2015-06-30T00:00:00.000000000',\n",
       "       '2015-07-01T00:00:00.000000000', '2015-07-02T00:00:00.000000000',\n",
       "       '2015-07-03T00:00:00.000000000', '2015-07-04T00:00:00.000000000',\n",
       "       '2015-07-05T00:00:00.000000000', '2015-07-06T00:00:00.000000000',\n",
       "       '2015-07-07T00:00:00.000000000', '2015-07-08T00:00:00.000000000',\n",
       "       '2015-07-09T00:00:00.000000000', '2015-07-10T00:00:00.000000000',\n",
       "       '2015-07-11T00:00:00.000000000', '2015-07-12T00:00:00.000000000',\n",
       "       '2015-07-13T00:00:00.000000000', '2015-07-14T00:00:00.000000000',\n",
       "       '2015-07-15T00:00:00.000000000', '2015-07-16T00:00:00.000000000',\n",
       "       '2015-07-17T00:00:00.000000000', '2015-07-18T00:00:00.000000000',\n",
       "       '2015-07-19T00:00:00.000000000', '2015-07-20T00:00:00.000000000',\n",
       "       '2015-07-21T00:00:00.000000000', '2015-07-22T00:00:00.000000000',\n",
       "       '2015-07-23T00:00:00.000000000', '2015-07-24T00:00:00.000000000',\n",
       "       '2015-07-25T00:00:00.000000000', '2015-07-26T00:00:00.000000000',\n",
       "       '2015-07-27T00:00:00.000000000', '2015-07-28T00:00:00.000000000',\n",
       "       '2015-07-29T00:00:00.000000000', '2015-07-30T00:00:00.000000000',\n",
       "       '2015-07-31T00:00:00.000000000', '2015-08-01T00:00:00.000000000',\n",
       "       '2015-08-02T00:00:00.000000000', '2015-08-03T00:00:00.000000000',\n",
       "       '2015-08-04T00:00:00.000000000', '2015-08-05T00:00:00.000000000',\n",
       "       '2015-08-06T00:00:00.000000000', '2015-08-07T00:00:00.000000000',\n",
       "       '2015-08-08T00:00:00.000000000', '2015-08-09T00:00:00.000000000',\n",
       "       '2015-08-10T00:00:00.000000000', '2015-08-11T00:00:00.000000000',\n",
       "       '2015-08-12T00:00:00.000000000', '2015-08-13T00:00:00.000000000',\n",
       "       '2015-08-14T00:00:00.000000000', '2015-08-15T00:00:00.000000000',\n",
       "       '2015-08-16T00:00:00.000000000', '2015-08-17T00:00:00.000000000',\n",
       "       '2015-08-18T00:00:00.000000000', '2015-08-19T00:00:00.000000000',\n",
       "       '2015-08-20T00:00:00.000000000', '2015-08-21T00:00:00.000000000',\n",
       "       '2015-08-22T00:00:00.000000000', '2015-08-23T00:00:00.000000000',\n",
       "       '2015-08-24T00:00:00.000000000', '2015-08-25T00:00:00.000000000',\n",
       "       '2015-08-26T00:00:00.000000000', '2015-08-27T00:00:00.000000000',\n",
       "       '2015-08-28T00:00:00.000000000', '2015-08-29T00:00:00.000000000',\n",
       "       '2015-08-30T00:00:00.000000000', '2015-08-31T00:00:00.000000000',\n",
       "       '2015-09-01T00:00:00.000000000', '2015-09-02T00:00:00.000000000',\n",
       "       '2015-09-03T00:00:00.000000000', '2015-09-04T00:00:00.000000000',\n",
       "       '2015-09-05T00:00:00.000000000', '2015-09-06T00:00:00.000000000',\n",
       "       '2015-09-07T00:00:00.000000000', '2015-09-08T00:00:00.000000000',\n",
       "       '2015-09-09T00:00:00.000000000', '2015-09-10T00:00:00.000000000',\n",
       "       '2015-09-11T00:00:00.000000000', '2015-09-12T00:00:00.000000000',\n",
       "       '2015-09-13T00:00:00.000000000', '2015-09-14T00:00:00.000000000',\n",
       "       '2015-09-15T00:00:00.000000000', '2015-09-16T00:00:00.000000000',\n",
       "       '2015-09-17T00:00:00.000000000', '2015-09-18T00:00:00.000000000',\n",
       "       '2015-09-19T00:00:00.000000000', '2015-09-20T00:00:00.000000000',\n",
       "       '2015-09-21T00:00:00.000000000', '2015-09-22T00:00:00.000000000',\n",
       "       '2015-09-23T00:00:00.000000000', '2015-09-24T00:00:00.000000000',\n",
       "       '2015-09-25T00:00:00.000000000', '2015-09-26T00:00:00.000000000',\n",
       "       '2015-09-27T00:00:00.000000000', '2015-09-28T00:00:00.000000000',\n",
       "       '2015-09-29T00:00:00.000000000', '2015-09-30T00:00:00.000000000',\n",
       "       '2015-10-01T00:00:00.000000000', '2015-10-02T00:00:00.000000000',\n",
       "       '2015-10-03T00:00:00.000000000', '2015-10-04T00:00:00.000000000',\n",
       "       '2015-10-05T00:00:00.000000000', '2015-10-06T00:00:00.000000000',\n",
       "       '2015-10-07T00:00:00.000000000', '2015-10-08T00:00:00.000000000',\n",
       "       '2015-10-09T00:00:00.000000000', '2015-10-10T00:00:00.000000000',\n",
       "       '2015-10-11T00:00:00.000000000', '2015-10-12T00:00:00.000000000',\n",
       "       '2015-10-13T00:00:00.000000000', '2015-10-14T00:00:00.000000000',\n",
       "       '2015-10-15T00:00:00.000000000', '2015-10-16T00:00:00.000000000',\n",
       "       '2015-10-17T00:00:00.000000000', '2015-10-18T00:00:00.000000000',\n",
       "       '2015-10-19T00:00:00.000000000', '2015-10-20T00:00:00.000000000',\n",
       "       '2015-10-21T00:00:00.000000000', '2015-10-22T00:00:00.000000000',\n",
       "       '2015-10-23T00:00:00.000000000', '2015-10-24T00:00:00.000000000',\n",
       "       '2015-10-25T00:00:00.000000000', '2015-10-26T00:00:00.000000000',\n",
       "       '2015-10-27T00:00:00.000000000', '2015-10-28T00:00:00.000000000',\n",
       "       '2015-10-29T00:00:00.000000000', '2015-10-30T00:00:00.000000000',\n",
       "       '2015-10-31T00:00:00.000000000', '2015-11-01T00:00:00.000000000',\n",
       "       '2015-11-02T00:00:00.000000000', '2015-11-03T00:00:00.000000000',\n",
       "       '2015-11-04T00:00:00.000000000', '2015-11-05T00:00:00.000000000',\n",
       "       '2015-11-06T00:00:00.000000000', '2015-11-07T00:00:00.000000000',\n",
       "       '2015-11-08T00:00:00.000000000', '2015-11-09T00:00:00.000000000',\n",
       "       '2015-11-10T00:00:00.000000000', '2015-11-11T00:00:00.000000000',\n",
       "       '2015-11-12T00:00:00.000000000', '2015-11-13T00:00:00.000000000',\n",
       "       '2015-11-14T00:00:00.000000000', '2015-11-15T00:00:00.000000000',\n",
       "       '2015-11-16T00:00:00.000000000', '2015-11-17T00:00:00.000000000',\n",
       "       '2015-11-18T00:00:00.000000000', '2015-11-19T00:00:00.000000000',\n",
       "       '2015-11-20T00:00:00.000000000', '2015-11-21T00:00:00.000000000',\n",
       "       '2015-11-22T00:00:00.000000000', '2015-11-23T00:00:00.000000000',\n",
       "       '2015-11-24T00:00:00.000000000', '2015-11-25T00:00:00.000000000',\n",
       "       '2015-11-26T00:00:00.000000000', '2015-11-27T00:00:00.000000000',\n",
       "       '2015-11-28T00:00:00.000000000', '2015-11-29T00:00:00.000000000',\n",
       "       '2015-11-30T00:00:00.000000000', '2015-12-01T00:00:00.000000000',\n",
       "       '2015-12-02T00:00:00.000000000', '2015-12-03T00:00:00.000000000',\n",
       "       '2015-12-04T00:00:00.000000000', '2015-12-05T00:00:00.000000000',\n",
       "       '2015-12-06T00:00:00.000000000', '2015-12-07T00:00:00.000000000',\n",
       "       '2015-12-08T00:00:00.000000000', '2015-12-09T00:00:00.000000000',\n",
       "       '2015-12-10T00:00:00.000000000', '2015-12-11T00:00:00.000000000',\n",
       "       '2015-12-12T00:00:00.000000000', '2015-12-13T00:00:00.000000000',\n",
       "       '2015-12-14T00:00:00.000000000', '2015-12-15T00:00:00.000000000',\n",
       "       '2015-12-16T00:00:00.000000000', '2015-12-17T00:00:00.000000000',\n",
       "       '2015-12-18T00:00:00.000000000', '2015-12-19T00:00:00.000000000',\n",
       "       '2015-12-20T00:00:00.000000000', '2015-12-21T00:00:00.000000000',\n",
       "       '2015-12-22T00:00:00.000000000', '2015-12-23T00:00:00.000000000',\n",
       "       '2015-12-24T00:00:00.000000000', '2015-12-25T00:00:00.000000000',\n",
       "       '2015-12-26T00:00:00.000000000', '2015-12-27T00:00:00.000000000',\n",
       "       '2015-12-28T00:00:00.000000000', '2015-12-29T00:00:00.000000000',\n",
       "       '2015-12-30T00:00:00.000000000', '2015-12-31T00:00:00.000000000',\n",
       "       '2016-01-01T00:00:00.000000000', '2016-01-02T00:00:00.000000000',\n",
       "       '2016-01-03T00:00:00.000000000', '2016-01-04T00:00:00.000000000',\n",
       "       '2016-01-05T00:00:00.000000000', '2016-01-06T00:00:00.000000000',\n",
       "       '2016-01-07T00:00:00.000000000', '2016-01-08T00:00:00.000000000',\n",
       "       '2016-01-09T00:00:00.000000000', '2016-01-10T00:00:00.000000000',\n",
       "       '2016-01-11T00:00:00.000000000', '2016-01-12T00:00:00.000000000',\n",
       "       '2016-01-13T00:00:00.000000000', '2016-01-14T00:00:00.000000000',\n",
       "       '2016-01-15T00:00:00.000000000', '2016-01-16T00:00:00.000000000',\n",
       "       '2016-01-17T00:00:00.000000000', '2016-01-18T00:00:00.000000000',\n",
       "       '2016-01-19T00:00:00.000000000', '2016-01-20T00:00:00.000000000',\n",
       "       '2016-01-21T00:00:00.000000000', '2016-01-22T00:00:00.000000000',\n",
       "       '2016-01-23T00:00:00.000000000', '2016-01-24T00:00:00.000000000',\n",
       "       '2016-01-25T00:00:00.000000000', '2016-01-26T00:00:00.000000000',\n",
       "       '2016-01-27T00:00:00.000000000', '2016-01-28T00:00:00.000000000',\n",
       "       '2016-01-29T00:00:00.000000000', '2016-01-30T00:00:00.000000000',\n",
       "       '2016-01-31T00:00:00.000000000', '2016-02-01T00:00:00.000000000',\n",
       "       '2016-02-02T00:00:00.000000000', '2016-02-03T00:00:00.000000000',\n",
       "       '2016-02-04T00:00:00.000000000', '2016-02-05T00:00:00.000000000',\n",
       "       '2016-02-06T00:00:00.000000000', '2016-02-07T00:00:00.000000000',\n",
       "       '2016-02-08T00:00:00.000000000', '2016-02-09T00:00:00.000000000',\n",
       "       '2016-02-10T00:00:00.000000000', '2016-02-11T00:00:00.000000000',\n",
       "       '2016-02-12T00:00:00.000000000', '2016-02-13T00:00:00.000000000',\n",
       "       '2016-02-14T00:00:00.000000000', '2016-02-15T00:00:00.000000000',\n",
       "       '2016-02-16T00:00:00.000000000', '2016-02-17T00:00:00.000000000',\n",
       "       '2016-02-18T00:00:00.000000000', '2016-02-19T00:00:00.000000000',\n",
       "       '2016-02-20T00:00:00.000000000', '2016-02-21T00:00:00.000000000',\n",
       "       '2016-02-22T00:00:00.000000000', '2016-02-23T00:00:00.000000000',\n",
       "       '2016-02-24T00:00:00.000000000', '2016-02-25T00:00:00.000000000',\n",
       "       '2016-02-26T00:00:00.000000000', '2016-02-27T00:00:00.000000000',\n",
       "       '2016-02-28T00:00:00.000000000', '2016-02-29T00:00:00.000000000',\n",
       "       '2016-03-01T00:00:00.000000000', '2016-03-02T00:00:00.000000000',\n",
       "       '2016-03-03T00:00:00.000000000', '2016-03-04T00:00:00.000000000',\n",
       "       '2016-03-05T00:00:00.000000000', '2016-03-06T00:00:00.000000000',\n",
       "       '2016-03-07T00:00:00.000000000', '2016-03-08T00:00:00.000000000',\n",
       "       '2016-03-09T00:00:00.000000000', '2016-03-10T00:00:00.000000000',\n",
       "       '2016-03-11T00:00:00.000000000', '2016-03-12T00:00:00.000000000',\n",
       "       '2016-03-13T00:00:00.000000000', '2016-03-14T00:00:00.000000000',\n",
       "       '2016-03-15T00:00:00.000000000', '2016-03-16T00:00:00.000000000',\n",
       "       '2016-03-17T00:00:00.000000000', '2016-03-18T00:00:00.000000000',\n",
       "       '2016-03-19T00:00:00.000000000', '2016-03-20T00:00:00.000000000',\n",
       "       '2016-03-21T00:00:00.000000000', '2016-03-22T00:00:00.000000000',\n",
       "       '2016-03-23T00:00:00.000000000', '2016-03-24T00:00:00.000000000',\n",
       "       '2016-03-25T00:00:00.000000000', '2016-03-26T00:00:00.000000000',\n",
       "       '2016-03-27T00:00:00.000000000', '2016-03-28T00:00:00.000000000',\n",
       "       '2016-03-29T00:00:00.000000000', '2016-03-30T00:00:00.000000000',\n",
       "       '2016-03-31T00:00:00.000000000', '2016-04-01T00:00:00.000000000',\n",
       "       '2016-04-02T00:00:00.000000000', '2016-04-03T00:00:00.000000000',\n",
       "       '2016-04-04T00:00:00.000000000', '2016-04-05T00:00:00.000000000',\n",
       "       '2016-04-06T00:00:00.000000000', '2016-04-07T00:00:00.000000000',\n",
       "       '2016-04-08T00:00:00.000000000', '2016-04-09T00:00:00.000000000',\n",
       "       '2016-04-10T00:00:00.000000000', '2016-04-11T00:00:00.000000000',\n",
       "       '2016-04-12T00:00:00.000000000', '2016-04-13T00:00:00.000000000',\n",
       "       '2016-04-14T00:00:00.000000000', '2016-04-15T00:00:00.000000000',\n",
       "       '2016-04-16T00:00:00.000000000', '2016-04-17T00:00:00.000000000',\n",
       "       '2016-04-18T00:00:00.000000000', '2016-04-19T00:00:00.000000000',\n",
       "       '2016-04-20T00:00:00.000000000', '2016-04-21T00:00:00.000000000',\n",
       "       '2016-04-22T00:00:00.000000000', '2016-04-23T00:00:00.000000000',\n",
       "       '2016-04-24T00:00:00.000000000', '2016-04-25T00:00:00.000000000',\n",
       "       '2016-04-26T00:00:00.000000000', '2016-04-27T00:00:00.000000000',\n",
       "       '2016-04-28T00:00:00.000000000', '2016-04-29T00:00:00.000000000',\n",
       "       '2016-04-30T00:00:00.000000000', '2016-05-01T00:00:00.000000000',\n",
       "       '2016-05-02T00:00:00.000000000', '2016-05-03T00:00:00.000000000',\n",
       "       '2016-05-04T00:00:00.000000000', '2016-05-05T00:00:00.000000000',\n",
       "       '2016-05-06T00:00:00.000000000', '2016-05-07T00:00:00.000000000',\n",
       "       '2016-05-08T00:00:00.000000000', '2016-05-09T00:00:00.000000000',\n",
       "       '2016-05-10T00:00:00.000000000', '2016-05-11T00:00:00.000000000',\n",
       "       '2016-05-12T00:00:00.000000000', '2016-05-13T00:00:00.000000000',\n",
       "       '2016-05-14T00:00:00.000000000', '2016-05-15T00:00:00.000000000',\n",
       "       '2016-05-16T00:00:00.000000000', '2016-05-17T00:00:00.000000000',\n",
       "       '2016-05-18T00:00:00.000000000', '2016-05-19T00:00:00.000000000',\n",
       "       '2016-05-20T00:00:00.000000000', '2016-05-21T00:00:00.000000000',\n",
       "       '2016-05-22T00:00:00.000000000', '2016-05-23T00:00:00.000000000',\n",
       "       '2016-05-24T00:00:00.000000000', '2016-05-25T00:00:00.000000000',\n",
       "       '2016-05-26T00:00:00.000000000', '2016-05-27T00:00:00.000000000',\n",
       "       '2016-05-28T00:00:00.000000000', '2016-05-29T00:00:00.000000000',\n",
       "       '2016-05-30T00:00:00.000000000', '2016-05-31T00:00:00.000000000',\n",
       "       '2016-06-01T00:00:00.000000000', '2016-06-02T00:00:00.000000000',\n",
       "       '2016-06-03T00:00:00.000000000', '2016-06-04T00:00:00.000000000',\n",
       "       '2016-06-05T00:00:00.000000000', '2016-06-06T00:00:00.000000000',\n",
       "       '2016-06-07T00:00:00.000000000', '2016-06-08T00:00:00.000000000',\n",
       "       '2016-06-09T00:00:00.000000000', '2016-06-10T00:00:00.000000000',\n",
       "       '2016-06-11T00:00:00.000000000', '2016-06-12T00:00:00.000000000',\n",
       "       '2016-06-13T00:00:00.000000000', '2016-06-14T00:00:00.000000000',\n",
       "       '2016-06-15T00:00:00.000000000', '2016-06-16T00:00:00.000000000',\n",
       "       '2016-06-17T00:00:00.000000000', '2016-06-18T00:00:00.000000000',\n",
       "       '2016-06-19T00:00:00.000000000', '2016-06-20T00:00:00.000000000',\n",
       "       '2016-06-21T00:00:00.000000000', '2016-06-22T00:00:00.000000000',\n",
       "       '2016-06-23T00:00:00.000000000', '2016-06-24T00:00:00.000000000',\n",
       "       '2016-06-25T00:00:00.000000000', '2016-06-26T00:00:00.000000000',\n",
       "       '2016-06-27T00:00:00.000000000', '2016-06-28T00:00:00.000000000',\n",
       "       '2016-06-29T00:00:00.000000000', '2016-06-30T00:00:00.000000000',\n",
       "       '2016-07-01T00:00:00.000000000', '2016-07-02T00:00:00.000000000',\n",
       "       '2016-07-03T00:00:00.000000000', '2016-07-04T00:00:00.000000000',\n",
       "       '2016-07-05T00:00:00.000000000', '2016-07-06T00:00:00.000000000',\n",
       "       '2016-07-07T00:00:00.000000000', '2016-07-08T00:00:00.000000000',\n",
       "       '2016-07-09T00:00:00.000000000', '2016-07-10T00:00:00.000000000',\n",
       "       '2016-07-11T00:00:00.000000000', '2016-07-12T00:00:00.000000000',\n",
       "       '2016-07-13T00:00:00.000000000', '2016-07-14T00:00:00.000000000',\n",
       "       '2016-07-15T00:00:00.000000000', '2016-07-16T00:00:00.000000000',\n",
       "       '2016-07-17T00:00:00.000000000', '2016-07-18T00:00:00.000000000',\n",
       "       '2016-07-19T00:00:00.000000000', '2016-07-20T00:00:00.000000000',\n",
       "       '2016-07-21T00:00:00.000000000', '2016-07-22T00:00:00.000000000',\n",
       "       '2016-07-23T00:00:00.000000000', '2016-07-24T00:00:00.000000000',\n",
       "       '2016-07-25T00:00:00.000000000', '2016-07-26T00:00:00.000000000',\n",
       "       '2016-07-27T00:00:00.000000000', '2016-07-28T00:00:00.000000000',\n",
       "       '2016-07-29T00:00:00.000000000', '2016-07-30T00:00:00.000000000',\n",
       "       '2016-07-31T00:00:00.000000000', '2016-08-01T00:00:00.000000000',\n",
       "       '2016-08-02T00:00:00.000000000', '2016-08-03T00:00:00.000000000',\n",
       "       '2016-08-04T00:00:00.000000000', '2016-08-05T00:00:00.000000000',\n",
       "       '2016-08-06T00:00:00.000000000', '2016-08-07T00:00:00.000000000',\n",
       "       '2016-08-08T00:00:00.000000000', '2016-08-09T00:00:00.000000000',\n",
       "       '2016-08-10T00:00:00.000000000', '2016-08-11T00:00:00.000000000',\n",
       "       '2016-08-12T00:00:00.000000000', '2016-08-13T00:00:00.000000000',\n",
       "       '2016-08-14T00:00:00.000000000', '2016-08-15T00:00:00.000000000',\n",
       "       '2016-08-16T00:00:00.000000000', '2016-08-17T00:00:00.000000000',\n",
       "       '2016-08-18T00:00:00.000000000', '2016-08-19T00:00:00.000000000',\n",
       "       '2016-08-20T00:00:00.000000000', '2016-08-21T00:00:00.000000000',\n",
       "       '2016-08-22T00:00:00.000000000', '2016-08-23T00:00:00.000000000',\n",
       "       '2016-08-24T00:00:00.000000000', '2016-08-25T00:00:00.000000000',\n",
       "       '2016-08-26T00:00:00.000000000', '2016-08-27T00:00:00.000000000',\n",
       "       '2016-08-28T00:00:00.000000000', '2016-08-29T00:00:00.000000000',\n",
       "       '2016-08-30T00:00:00.000000000', '2016-08-31T00:00:00.000000000',\n",
       "       '2016-09-01T00:00:00.000000000', '2016-09-02T00:00:00.000000000',\n",
       "       '2016-09-03T00:00:00.000000000', '2016-09-04T00:00:00.000000000',\n",
       "       '2016-09-05T00:00:00.000000000', '2016-09-06T00:00:00.000000000',\n",
       "       '2016-09-07T00:00:00.000000000', '2016-09-08T00:00:00.000000000',\n",
       "       '2016-09-09T00:00:00.000000000', '2016-09-10T00:00:00.000000000',\n",
       "       '2016-09-11T00:00:00.000000000', '2016-09-12T00:00:00.000000000',\n",
       "       '2016-09-13T00:00:00.000000000', '2016-09-14T00:00:00.000000000',\n",
       "       '2016-09-15T00:00:00.000000000', '2016-09-16T00:00:00.000000000',\n",
       "       '2016-09-17T00:00:00.000000000', '2016-09-18T00:00:00.000000000',\n",
       "       '2016-09-19T00:00:00.000000000', '2016-09-20T00:00:00.000000000',\n",
       "       '2016-09-21T00:00:00.000000000', '2016-09-22T00:00:00.000000000',\n",
       "       '2016-09-23T00:00:00.000000000', '2016-09-24T00:00:00.000000000',\n",
       "       '2016-09-25T00:00:00.000000000', '2016-09-26T00:00:00.000000000',\n",
       "       '2016-09-27T00:00:00.000000000', '2016-09-28T00:00:00.000000000',\n",
       "       '2016-09-29T00:00:00.000000000', '2016-09-30T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "df_final.record_date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = df_final.drop(['record_date'],1)\n",
    "df_final.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ### 生成训练集和测试集\n",
    "\n",
    "# # import pandas as pd\n",
    "# # df_final = pd.read_csv('train.csv')\n",
    "\n",
    "# # # df_final = df_final.drop('record_date',1)\n",
    "\n",
    "# final_train_data = df_final[~((df_final.year==2016)&(df_final.month==9))].drop(['power_consumption'],1)\n",
    "# final_train_data = final_train_data.astype(float)\n",
    "# final_test_data = df_final[((df_final.year==2016)&(df_final.month==9))].drop(['power_consumption'],1)\n",
    "# final_test_data = final_test_data.astype(float)\n",
    "# train_target = df_final[~((df_final.year==2016)&(df_final.month==9))][['power_consumption']]\n",
    "\n",
    "# # # train_lgb = final_train_data.copy()\n",
    "# # # train_lgb[['dow','doy','day','month','year']] = train_lgb[['dow','doy','day','month','year']]\\\n",
    "# # # .astype(str)\n",
    "# # # test_lgb = final_test_data.copy()\n",
    "# # # test_lgb[['dow','doy','day','month','year']] = test_lgb[['dow','doy','day','month','year',]]\\\n",
    "# # # .astype(str)\n",
    "\n",
    "# # # X_lgb = train_lgb.values\n",
    "# # # y_lgb = train_target.values.reshape(train_target.values.shape[0],)\n",
    "# # # # print y_lgb[0]\n",
    "# # # # print X_lgb[0,:]\n",
    "\n",
    "# # # #随机敲定一组参数跑模型\n",
    "# # # # import lightgbm as lgb\n",
    "# # # from sklearn.metrics import mean_squared_error\n",
    "# # # import matplotlib.pyplot as plt\n",
    "# # # %matplotlib inline\n",
    "# # # # create dataset for lightgbm\n",
    "# # # lgb_train = lgb.Dataset(X_lgb, y_lgb)\n",
    "# # # # specify your configurations as a dict\n",
    "# # # params = {\n",
    "# # #     'num_leaves': 1024,\n",
    "# # #     'learning_rate':0.42,\n",
    "# # #     'n_estimators':30,\n",
    "# # #     'feature_fraction': 1,\n",
    "# # #     'bagging_fraction': 0.8,\n",
    "# # #     'bagging_freq': 5\n",
    "# # # }\n",
    "\n",
    "# # # print('Start training...')\n",
    "# # # # train\n",
    "\n",
    "# # # evals_result = {}  # to record eval results for plotting\n",
    "\n",
    "# # # gbm = lgb.train(params,\n",
    "# # #                 lgb_train,\n",
    "# # #                 num_boost_round=30,\n",
    "# # #                 feature_name=list(final_train_data.columns))\n",
    "\n",
    "\n",
    "# # # # gbm = lgb.train(params,\n",
    "# # # #                 lgb_train,\n",
    "# # # #                 num_boost_round=30,\n",
    "# # # # #                 valid_sets=[lgb_train, lgb_test],\n",
    "# # # #                 feature_name=list(final_train_data.columns)),\n",
    "# # # # #                 categorical_feature=[21],\n",
    "# # # #                 evals_result=evals_result,\n",
    "# # # # #                 verbose_eval=10\n",
    "# # # #         )\n",
    "# # # df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重要度排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# print('Plot feature importances...')\n",
    "# ax = lgb.plot_importance(gbm, max_num_features=10)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# commit_df = pd.date_range('2016/9/1', periods=30, freq='D')\n",
    "# commit_df = pd.DataFrame(commit_df)\n",
    "# commit_df.columns = ['predict_date']\n",
    "# y_predict = gbm.predict(test_lgb.values)\n",
    "# commit_df['predict_power_consumption'] = pd.DataFrame(y_predict).astype('int')\n",
    "# commit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 生成提交结果文件\n",
    "# # 转换日期格式 \n",
    "\n",
    "# from datetime import datetime \n",
    "\n",
    "# def timetransform(t):\n",
    "#     t = str(t)[0:10]\n",
    "#     time = datetime.strptime(t, '%Y-%m-%d')\n",
    "#     res = time.strftime('%Y%m%d')\n",
    "#     return res\n",
    "\n",
    "# commit_df['predict_date'] = commit_df['predict_date'].apply(timetransform)\n",
    "\n",
    "# commit_df.head()\n",
    "# commit_df.to_csv('Tianchi_power_predict_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 读入最好的成绩 做参考\n",
    "# ref = pd.read_csv('predict_ref0529.csv')\n",
    "# # test_x = pd.read_csv('test.csv')\n",
    "# # train_y = train['power_consumption']\n",
    "# # train_X = train.drop('power_consumption',axis=1)\n",
    "# # train_X.shape\n",
    "# # ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 读取当前预测结果\n",
    "# cur = pd.read_csv('Tianchi_power_predict_table.csv')\n",
    "# # test_x = pd.read_csv('test.csv')\n",
    "# # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y2 = cur['predict_power_consumption'].values\n",
    "# x = cur['predict_date'].values\n",
    "# y = ref['predict_power_consumption'].values\n",
    "\n",
    "# plt.plot(x, y)\n",
    "# plt.plot(x,y2)\n",
    "# plt.legend(['ref','cur'],loc = 0, ncol = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 尝试不同模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_final.head()\n",
    "# df_final.shape\n",
    "# commit_df = pd.date_range('2016/9/1', periods=30, freq='D')\n",
    "# commit_df = pd.DataFrame(commit_df)\n",
    "# commit_df.columns = ['predict_date']\n",
    "# # y_predict = gbm.predict(test_lgb.values)\n",
    "# commit_df['predict_power_consumption'] = pd.DataFrame(y_predict).astype('int')\n",
    "# commit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import Perceptron\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>first_half</th>\n",
       "      <th>second_half</th>\n",
       "      <th>month_period_1</th>\n",
       "      <th>month_period_2</th>\n",
       "      <th>month_period_3</th>\n",
       "      <th>week_period_1</th>\n",
       "      <th>week_period_2</th>\n",
       "      <th>week_period_3</th>\n",
       "      <th>week_period_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.145833</td>\n",
       "      <td>-1.223102e+06</td>\n",
       "      <td>-342783.154545</td>\n",
       "      <td>-1352485.7</td>\n",
       "      <td>-93716.5375</td>\n",
       "      <td>-220744.014286</td>\n",
       "      <td>-739169.857143</td>\n",
       "      <td>-1.042484e+06</td>\n",
       "      <td>252348.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.145833</td>\n",
       "      <td>-1.223102e+06</td>\n",
       "      <td>-342783.154545</td>\n",
       "      <td>-1352485.7</td>\n",
       "      <td>-93716.5375</td>\n",
       "      <td>-220744.014286</td>\n",
       "      <td>-739169.857143</td>\n",
       "      <td>-1.042484e+06</td>\n",
       "      <td>252348.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.145833</td>\n",
       "      <td>-1.223102e+06</td>\n",
       "      <td>-342783.154545</td>\n",
       "      <td>-1352485.7</td>\n",
       "      <td>-93716.5375</td>\n",
       "      <td>-220744.014286</td>\n",
       "      <td>-739169.857143</td>\n",
       "      <td>-1.042484e+06</td>\n",
       "      <td>252348.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.145833</td>\n",
       "      <td>-1.223102e+06</td>\n",
       "      <td>-342783.154545</td>\n",
       "      <td>-1352485.7</td>\n",
       "      <td>-93716.5375</td>\n",
       "      <td>-220744.014286</td>\n",
       "      <td>-739169.857143</td>\n",
       "      <td>-1.042484e+06</td>\n",
       "      <td>252348.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.795163e+06</td>\n",
       "      <td>769697.864999</td>\n",
       "      <td>-674272.145833</td>\n",
       "      <td>-1.223102e+06</td>\n",
       "      <td>-342783.154545</td>\n",
       "      <td>-1352485.7</td>\n",
       "      <td>-93716.5375</td>\n",
       "      <td>-220744.014286</td>\n",
       "      <td>-739169.857143</td>\n",
       "      <td>-1.042484e+06</td>\n",
       "      <td>252348.357143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dow   doy  day month    year          mean            std     first_half  \\\n",
       "0  6.0  60.0  1.0   3.0  2015.0  2.795163e+06  769697.864999 -674272.145833   \n",
       "1  0.0  61.0  2.0   3.0  2015.0  2.795163e+06  769697.864999 -674272.145833   \n",
       "2  1.0  62.0  3.0   3.0  2015.0  2.795163e+06  769697.864999 -674272.145833   \n",
       "3  2.0  63.0  4.0   3.0  2015.0  2.795163e+06  769697.864999 -674272.145833   \n",
       "4  3.0  64.0  5.0   3.0  2015.0  2.795163e+06  769697.864999 -674272.145833   \n",
       "\n",
       "    second_half  month_period_1  month_period_2  month_period_3  \\\n",
       "0 -1.223102e+06  -342783.154545      -1352485.7     -93716.5375   \n",
       "1 -1.223102e+06  -342783.154545      -1352485.7     -93716.5375   \n",
       "2 -1.223102e+06  -342783.154545      -1352485.7     -93716.5375   \n",
       "3 -1.223102e+06  -342783.154545      -1352485.7     -93716.5375   \n",
       "4 -1.223102e+06  -342783.154545      -1352485.7     -93716.5375   \n",
       "\n",
       "   week_period_1  week_period_2  week_period_3  week_period_4  \n",
       "0 -220744.014286 -739169.857143  -1.042484e+06  252348.357143  \n",
       "1 -220744.014286 -739169.857143  -1.042484e+06  252348.357143  \n",
       "2 -220744.014286 -739169.857143  -1.042484e+06  252348.357143  \n",
       "3 -220744.014286 -739169.857143  -1.042484e+06  252348.357143  \n",
       "4 -220744.014286 -739169.857143  -1.042484e+06  252348.357143  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# train = df_final\n",
    "# x_test = train[train.]\n",
    "# y = train['power_consumption']\n",
    "# X = train.drop('power_consumption',axis=1)\n",
    "\n",
    "\n",
    "final_train_data = df_final[~((df_final.year==2016)&(df_final.month==9))].drop(['power_consumption'],1)\n",
    "final_train_data = final_train_data.astype(float)\n",
    "final_test_data = df_final[((df_final.year==2016)&(df_final.month==9))].drop(['power_consumption'],1)\n",
    "final_test_data = final_test_data.astype(float)\n",
    "train_target = df_final[~((df_final.year==2016)&(df_final.month==9))][['power_consumption']]\n",
    "\n",
    "train = final_train_data.copy()\n",
    "train[['dow','doy','day','month','year']] = train[['dow','doy','day','month','year']]\\\n",
    ".astype(str)\n",
    "test = final_test_data.copy()\n",
    "test[['dow','doy','day','month','year']] = test[['dow','doy','day','month','year',]]\\\n",
    ".astype(str)\n",
    "\n",
    "X_lgb = train.values\n",
    "y_lgb = train_target.values.reshape(train_target.values.shape[0],)\n",
    "# print y_lgb[0]\n",
    "# print X_lgb[0,:]\n",
    "train.dtypes#.shape[0]\n",
    "\n",
    "train.shape\n",
    "test.shape\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合 blending.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1  \n",
    "\n",
    "# 下面的函数要做CV, 所以把label 添加回train \n",
    "# train['power_consumption'] = train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestRegressor(bootstrap=True, criterion='gini', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "indices are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b2ad58fc806a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shujinhuang/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shujinhuang/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shujinhuang/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1668\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shujinhuang/anaconda3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   3953\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3955\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shujinhuang/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n)\u001b[0m\n\u001b[1;32m   1871\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# step 2 \n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "# import load_data\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "def logloss(attempt, actual, epsilon=1.0e-15):\n",
    "    \"\"\"Logloss, i.e. the score of the bioresponse competition.\n",
    "    \"\"\"\n",
    "    attempt = np.clip(attempt, epsilon, 1.0-epsilon)\n",
    "    return - np.mean(actual * np.log(attempt) +\n",
    "                     (1.0 - actual) * np.log(1.0 - attempt))\n",
    "\n",
    "\n",
    "np.random.seed(0)  # seed to shuffle the train set\n",
    "\n",
    "n_folds = 10\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "# X, y, X_submission = load_data.load()\n",
    "X, y, X_submission = train, train_target, test#load_data.load()\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "# skf = list(StratifiedKFold(y, n_folds))\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "skf = KFold(ntrain, n_folds=n_folds, shuffle=shuffle)\n",
    "\n",
    "# clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "#         RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "#         ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "#         ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "#         GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)]\n",
    "\n",
    "clfs = [RandomForestRegressor(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "#         RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "        ExtraTreesRegressor(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "#         ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingRegressor(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)\n",
    "       ]\n",
    "\n",
    "# print \"Creating train and test sets for blending.\"\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print (\"Fold\", i)\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:, 1]\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "# print\n",
    "print (\"Blending.\")\n",
    "clf = LogisticRegression()\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print (\"Linear stretch of predictions to [0,1]\")\n",
    "y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "print (\"Saving Results.\")\n",
    "tmp = np.vstack([range(1, len(y_submission)+1), y_submission]).T\n",
    "np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n",
    "           header='MoleculeId,PredictedProbability', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##step 2\n",
    "\n",
    "# 十月份\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold;\n",
    "\n",
    "\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "        \n",
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 16)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "# x_test\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3\n",
    "\n",
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "# ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "# gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "# svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 4\n",
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train['power_consumption'].ravel()\n",
    "train = train.drop(['power_consumption'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test.values # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "\n",
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "# ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "# gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "# svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09266987  0.20536475  0.12792205  0.04117992  0.01204066  0.05750835\n",
      "  0.02477244  0.04435532  0.04483705  0.03892727  0.02624355  0.05429825\n",
      "  0.02662782  0.01952569  0.0603774   0.12334961]\n",
      "[ 0.13616804  0.17790973  0.15263787  0.04578941  0.08864963  0.04019556\n",
      "  0.01578004  0.02082128  0.03870626  0.02113124  0.02961805  0.05351777\n",
      "  0.01981632  0.01766733  0.05536016  0.0862313 ]\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "\n",
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "# ada_feature = ada.feature_importances(x_train, y_train)\n",
    "# gb_feature = gb.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[13:04:22] src/objective/regression_obj.cc:108: label must be in [0,1] for logistic regression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-f16517ea50b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m  \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m  \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m  scale_pos_weight=1).fit(x_train, y_train)\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/ds/local/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[0;32m    249\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                               verbose_eval=verbose)\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/ds/local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/ds/local/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/ds/local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/ds/local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [13:04:22] src/objective/regression_obj.cc:108: label must be in [0,1] for logistic regression"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "# second level predictions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "#      'ExtraTrees': et_oof_train.ravel(),\n",
    "# #      'AdaBoost': ada_oof_train.ravel(),\n",
    "# #       'GradientBoost': gb_oof_train.ravel()\n",
    "#     })\n",
    "# base_predictions_train.head()\n",
    "\n",
    "x_train = np.concatenate(( et_oof_train, rf_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test), axis=1)\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "    \n",
    "# clf = LogisticRegression()\n",
    "#     clf.fit(dataset_blend_train, y)\n",
    "#     y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "#     print \"Linear stretch of predictions to [0,1]\"\n",
    "#     y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "#     print \"Saving Results.\"\n",
    "#     tmp = np.vstack([range(1, len(y_submission)+1), y_submission]).T\n",
    "#     np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n",
    "#                header='MoleculeId,PredictedProbability', comments='')\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "        print j, clf\n",
    "        dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "        for i, (train, test) in enumerate(skf):\n",
    "            print \"Fold\", i\n",
    "            X_train = X[train]\n",
    "            y_train = y[train]\n",
    "            X_test = X[test]\n",
    "            y_test = y[test]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "            dataset_blend_train[test, j] = y_submission\n",
    "            dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:, 1]\n",
    "        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "    print\n",
    "    print \"Blending.\"\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(dataset_blend_train, y)\n",
    "    y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "    print \"Linear stretch of predictions to [0,1]\"\n",
    "    y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "    print \"Saving Results.\"\n",
    "    tmp = np.vstack([range(1, len(y_submission)+1), y_submission]).T\n",
    "    np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n",
    "               header='MoleculeId,PredictedProbability', comments='')\n",
    "# gbm = xgb.XGBRegressor(\n",
    "#     #learning_rate = 0.02,\n",
    "#  n_estimators= 2000,\n",
    "#  max_depth= 4,\n",
    "#  min_child_weight= 2,\n",
    "#  #gamma=1,\n",
    "#  gamma=0.9,                        \n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread= -1,\n",
    "#  scale_pos_weight=1).fit(x_train, y_train)\n",
    "\n",
    "# predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5d8236ec50>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAENCAYAAAAorJMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d823c0950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 7.5 画图比对\n",
    "ref = pd.read_csv('predict_ref0529.csv')\n",
    "\n",
    "# y2 = cur['predict_power_consumption'].values\n",
    "x = ref['predict_date'].values\n",
    "y = ref['predict_power_consumption'].values\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, predictions)\n",
    "plt.legend(['ref','cur'],loc = 0, ncol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 8\n",
    "# Generate Submission File \n",
    "\n",
    "# 生成提交结果文件\n",
    "# 转换日期格式 \n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "def timetransform(t):\n",
    "    t = str(t)[0:10]\n",
    "    time = datetime.strptime(t, '%Y-%m-%d')\n",
    "    res = time.strftime('%Y%m%d')\n",
    "    return res\n",
    "\n",
    "commit_df = pd.date_range('2016/9/1', periods=30, freq='D')\n",
    "commit_df = pd.DataFrame(commit_df)\n",
    "commit_df.columns = ['predict_date']\n",
    "# y_predict = gbm.predict(test_lgb.values)\n",
    "commit_df['predict_power_consumption'] = pd.DataFrame(predictions).astype('int')\n",
    "# commit_df\n",
    "commit_df['predict_date'] = commit_df['predict_date'].apply(timetransform)\n",
    "\n",
    "# commit_df.head()\n",
    "commit_df.to_csv('Tianchi_power_predict_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Put in our parameters for said classifiers\n",
    "# # Random Forest parameters\n",
    "# rf_params = {\n",
    "#     'n_jobs': -1,\n",
    "#     'n_estimators': 500,\n",
    "#      'warm_start': True, \n",
    "#      #'max_features': 0.2,t\n",
    "#     'max_depth': 6,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'max_features' : 'sqrt',\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "# # Extra Trees Parameters\n",
    "# et_params = {\n",
    "#     'n_jobs': -1,\n",
    "#     'n_estimators':500,\n",
    "#     #'max_features': 0.5,\n",
    "#     'max_depth': 8,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "# # AdaBoost parameters\n",
    "# ada_params = {\n",
    "#     'n_estimators': 500,\n",
    "#     'learning_rate' : 0.75\n",
    "# }\n",
    "\n",
    "# # Gradient Boosting parameters\n",
    "# gb_params = {\n",
    "#     'n_estimators': 500,\n",
    "#      #'max_features': 0.2,\n",
    "#     'max_depth': 5,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "# # Support Vector Classifier parameters \n",
    "# svc_params = {\n",
    "#     'kernel' : 'linear',\n",
    "#     'C' : 0.025\n",
    "#     }\n",
    "# # Create 5 objects that represent our 4 models\n",
    "# rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "# et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)    ##### 无法处理 float ？？？\n",
    "# ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "# gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "# svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "\n",
    "# # Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "# # y_train = train_target#.ravel()\n",
    "\n",
    "# # x_train = train.values # Creates an array of the train data\n",
    "# # x_test = test.values # Creats an array of the test data\n",
    "# y_train = train['power_consumption'].ravel()\n",
    "# train = train.drop(['power_consumption'], axis=1)\n",
    "# x_train = train.values # Creates an array of the train data\n",
    "# x_test = test.values \n",
    "\n",
    "# # Create our OOF train and test predictions. These base results will be used as new features\n",
    "# et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "# rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "# ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "# gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "# svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "# print(\"Training is complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_train = train['power_consumption'].ravel()\n",
    "# # y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Some useful parameters which will come in handy later on\n",
    "# ntrain = train.shape[0]\n",
    "# ntest = test.shape[0]\n",
    "# SEED = 0 # for reproducibility\n",
    "# NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "# kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# # Class to extend the Sklearn classifier\n",
    "# class SklearnHelper(object):\n",
    "#     def __init__(self, clf, seed=0, params=None):\n",
    "#         params['random_state'] = seed\n",
    "#         self.clf = clf(**params)\n",
    "\n",
    "#     def train(self, x_train, y_train):\n",
    "#         self.clf.fit(x_train, y_train)\n",
    "\n",
    "#     def predict(self, x):\n",
    "#         return self.clf.predict(x)\n",
    "    \n",
    "#     def fit(self,x,y):\n",
    "#         return self.clf.fit(x,y)\n",
    "    \n",
    "#     def feature_importances(self,x,y):\n",
    "#         print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# # Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 尝试stacking 来源 https://www.kaggle.com/eliotbarr/stacking-starter/code\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import skew\n",
    "# import xgboost as xgb\n",
    "# from sklearn.cross_validation import KFold\n",
    "# from sklearn.ensemble import ExtraTreesRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, Lasso\n",
    "# from math import sqrt\n",
    "\n",
    "\n",
    "# TARGET = 'SalePrice'\n",
    "# NFOLDS = 5\n",
    "# SEED = 0\n",
    "# NROWS = None\n",
    "# ntrain = train.shape[0]\n",
    "# ntest = test.shape[0]\n",
    "\n",
    "\n",
    "# #creating matrices for sklearn:\n",
    "\n",
    "# x_train = train#np.array(all_data[:train.shape[0]])\n",
    "# x_test = test#np.array(all_data[train.shape[0]:])\n",
    "# y_train = train_target#np.log(train[TARGET]+1)\n",
    "\n",
    "# kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n",
    "# class SklearnWrapper(object):\n",
    "#     def __init__(self, clf, seed=0, params=None):\n",
    "#         params['random_state'] = seed\n",
    "#         self.clf = clf(**params)\n",
    "\n",
    "#     def train(self, x_train, y_train):\n",
    "#         self.clf.fit(x_train, y_train)\n",
    "\n",
    "#     def predict(self, x):\n",
    "#         return self.clf.predict(x)\n",
    "\n",
    "\n",
    "# class XgbWrapper(object):\n",
    "#     def __init__(self, seed=0, params=None):\n",
    "#         self.param = params\n",
    "#         self.param['seed'] = seed\n",
    "#         self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "#     def train(self, x_train, y_train):\n",
    "#         dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "#         self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "#     def predict(self, x):\n",
    "#         return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "\n",
    "# def get_oof(clf):  # 出现错误 out of bounds, don't know why \n",
    "#     oof_train = np.zeros((ntrain,))\n",
    "#     oof_test = np.zeros((ntest,))\n",
    "#     oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "#     for i, (train_index, test_index) in enumerate(kf):\n",
    "#         x_tr = x_train[train_index]\n",
    "#         y_tr = y_train[train_index]\n",
    "#         x_te = x_train[test_index]\n",
    "\n",
    "#         clf.train(x_tr, y_tr)\n",
    "\n",
    "#         oof_train[test_index] = clf.predict(x_te)\n",
    "#         oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "#     oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "#     return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# et_params = {\n",
    "#     'n_jobs': 16,\n",
    "#     'n_estimators': 100,\n",
    "#     'max_features': 0.5,\n",
    "#     'max_depth': 12,\n",
    "#     'min_samples_leaf': 2,\n",
    "# }\n",
    "\n",
    "# rf_params = {\n",
    "#     'n_jobs': 16,\n",
    "#     'n_estimators': 100,\n",
    "#     'max_features': 0.2,\n",
    "#     'max_depth': 12,\n",
    "#     'min_samples_leaf': 2,\n",
    "# }\n",
    "\n",
    "# xgb_params = {\n",
    "#     'seed': 0,\n",
    "#     'colsample_bytree': 0.7,\n",
    "#     'silent': 1,\n",
    "#     'subsample': 0.7,\n",
    "#     'learning_rate': 0.075,\n",
    "#     'objective': 'reg:linear',\n",
    "#     'max_depth': 4,\n",
    "#     'num_parallel_tree': 1,\n",
    "#     'min_child_weight': 1,\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'nrounds': 500\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# rd_params={\n",
    "#     'alpha': 10\n",
    "# }\n",
    "\n",
    "\n",
    "# ls_params={\n",
    "#     'alpha': 0.005\n",
    "# }\n",
    "\n",
    "\n",
    "# xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "# et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "# rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "# rd = SklearnWrapper(clf=Ridge, seed=SEED, params=rd_params)\n",
    "# ls = SklearnWrapper(clf=Lasso, seed=SEED, params=ls_params)\n",
    "\n",
    "# xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "# et_oof_train, et_oof_test = get_oof(et)\n",
    "# rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "# rd_oof_train, rd_oof_test = get_oof(rd)\n",
    "# ls_oof_train, ls_oof_test = get_oof(ls)\n",
    "\n",
    "# print(\"XG-CV: {}\".format(sqrt(mean_squared_error(y_train, xg_oof_train))))\n",
    "# print(\"ET-CV: {}\".format(sqrt(mean_squared_error(y_train, et_oof_train))))\n",
    "# print(\"RF-CV: {}\".format(sqrt(mean_squared_error(y_train, rf_oof_train))))\n",
    "# print(\"RD-CV: {}\".format(sqrt(mean_squared_error(y_train, rd_oof_train))))\n",
    "# print(\"LS-CV: {}\".format(sqrt(mean_squared_error(y_train, ls_oof_train))))\n",
    "\n",
    "\n",
    "# x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train, rd_oof_train, ls_oof_train), axis=1)\n",
    "# x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test, rd_oof_test, ls_oof_test), axis=1)\n",
    "\n",
    "# print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "# dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "# xgb_params = {\n",
    "#     'seed': 0,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'silent': 1,\n",
    "#     'subsample': 0.6,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'objective': 'reg:linear',\n",
    "#     'max_depth': 1,\n",
    "#     'num_parallel_tree': 1,\n",
    "#     'min_child_weight': 1,\n",
    "#     'eval_metric': 'rmse',\n",
    "# }\n",
    "\n",
    "# res = xgb.cv(xgb_params, dtrain, num_boost_round=1000, nfold=4, seed=SEED, stratified=False,\n",
    "#              early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "# best_nrounds = res.shape[0] - 1\n",
    "# cv_mean = res.iloc[-1, 0]\n",
    "# cv_std = res.iloc[-1, 1]\n",
    "\n",
    "# print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "\n",
    "# gbdt = xgb.train(xgb_params, dtrain, best_nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # blending 寒老师给的资料\n",
    "# # 不清楚输入的数据格式应该是什么， 所以暂时放一放\n",
    "\n",
    "# from __future__ import division\n",
    "# import numpy as np\n",
    "# # import load_data\n",
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "# from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "\n",
    "# def logloss(attempt, actual, epsilon=1.0e-15):\n",
    "#     \"\"\"Logloss, i.e. the score of the bioresponse competition.\n",
    "#     \"\"\"\n",
    "#     attempt = np.clip(attempt, epsilon, 1.0-epsilon)\n",
    "#     return - np.mean(actual * np.log(attempt) +\n",
    "#                      (1.0 - actual) * np.log(1.0 - attempt))\n",
    "\n",
    "\n",
    "# np.random.seed(0)  # seed to shuffle the train set\n",
    "\n",
    "# n_folds = 10\n",
    "# verbose = True\n",
    "# shuffle = False\n",
    "\n",
    "# X, y, X_submission = train, train_target, test#load_data.load()\n",
    "\n",
    "# ntrain = train.shape[0]\n",
    "# ntest = test.shape[0]\n",
    "\n",
    "# #\n",
    "# kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "# # if shuffle:\n",
    "# #     idx = np.random.permutation(y.size)\n",
    "# #     X = X[idx]\n",
    "# #     y = y[idx]\n",
    "\n",
    "# # skf = list(StratifiedKFold(y, n_folds))\n",
    "\n",
    "# # xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "# # et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "# # rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "# # rd = SklearnWrapper(clf=Ridge, seed=SEED, params=rd_params)\n",
    "# # ls = SklearnWrapper(clf=Lasso, seed=SEED, params=ls_params)\n",
    "\n",
    "# xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "# et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "# rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "# rd = SklearnWrapper(clf=Ridge, seed=SEED, params=rd_params)\n",
    "# ls = SklearnWrapper(clf=Lasso, seed=SEED, params=ls_params)\n",
    "\n",
    "\n",
    "# clfs = [RandomForestRegressor(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "# #         RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "#         ExtraTreesRegressor(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "# #         ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "# #         GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)\n",
    "#        ]\n",
    "# # y\n",
    "# # print \"Creating train and test sets for blending.\"\n",
    "\n",
    "# dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "# dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))\n",
    "\n",
    "# for j, clf in enumerate(clfs):\n",
    "#     print j, clf\n",
    "#     dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "#     for i, (train, test) in enumerate(skf):\n",
    "#         print \"Fold\", i\n",
    "#         X_train = X[train]\n",
    "#         y_train = y[train]\n",
    "#         X_test = X[test]\n",
    "#         y_test = y[test]\n",
    "#         clf.fit(X_train, y_train)\n",
    "#         y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "#         dataset_blend_train[test, j] = y_submission\n",
    "#         dataset_blend_test_j[:, i] = clf.predict_proba(X_submission)[:, 1]\n",
    "#     dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "# print\n",
    "# print \"Blending.\"\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(dataset_blend_train, y)\n",
    "# y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "# print \"Linear stretch of predictions to [0,1]\"\n",
    "# y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "\n",
    "# print \"Saving Results.\"\n",
    "# tmp = np.vstack([range(1, len(y_submission)+1), y_submission]).T\n",
    "# np.savetxt(fname='submission.csv', X=tmp, fmt='%d,%0.9f',\n",
    "#            header='MoleculeId,PredictedProbability', comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 画图为准\n",
    "# # y2 = cur['predict_power_consumption'].values\n",
    "# x = cur['predict_date'].values\n",
    "# y = ref['predict_power_consumption'].values\n",
    "\n",
    "# # plt.plot(x, y)\n",
    "# # plt.plot(x,y2)\n",
    "# # plt.legend(['ref','cur'],loc = 0, ncol = 2)\n",
    "# plt.subplot()\n",
    "\n",
    "# models = [\n",
    "# #     ExtraTreesRegressor(),\n",
    "# ##     BaggingRegressor(),\n",
    "# #     RandomForestRegressor(),\n",
    "#     GradientBoostingRegressor(),\n",
    "#     ]\n",
    "\n",
    "# for model in models:\n",
    "#     model.fit(train,train_target)\n",
    "#     y2 = model.predict(test)\n",
    "#     plt.figure\n",
    "#     plt.plot(x, y)\n",
    "#     plt.plot(x,y2)\n",
    "#     #     plt.legend(['ref','cur'],loc = 0, ncol = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
