2017-07-18 
大数据-牛妞(3530548572) 10:21:35
@全体成员 【Attention】
大数据文摘数据分析项目招募进行中！！
[爱心] | 五十万条数据的实战机会

可能你想要大数据项目的实战机会
或许你渴望认识志同道个的各路大牛
或者仅仅想要体会志愿者协同合作的快乐
通通可以看过来！欢迎你加入我们！

 请认真填写报名表
http://bigdatadigest.mikecrm.com/l6511Xk
北京 - 柳振良(365696003) 18:36:47
今天一天群里好安静啊
易龙(16203670) 18:37:11
 
助教-杨晶(1542504647) 18:37:26
[群签到]请使用手机QQ进行查看。
北京 - 柳振良(365696003) 18:38:09
助教犯规，不到签到时间  
助教-杨晶(1542504647) 18:39:21
规则是我定的哦 
易龙(16203670) 18:40:09
[群签到]请使用手机QQ进行查看。
北京 - 柳振良(365696003) 18:40:20
 
广州-吴茂强(348606294) 19:29:37
[群签到]请使用手机QQ进行查看。
万如苑(496286316) 19:36:04
[群签到]请使用手机QQ进行查看。
杨亚强(782506796) 19:37:15
[群签到]请使用手机QQ进行查看。
欧睿智(3288302) 19:40:25
[群签到]请使用手机QQ进行查看。
赵百轶(932925940) 19:41:27
[群签到]请使用手机QQ进行查看。
助教-林镇<andy_linky@qq.com> 19:49:11
[群签到]请使用手机QQ进行查看。
花轮同学<mengvision@qq.com> 19:49:41
[群签到]请使用手机QQ进行查看。
Vincent(1733990589) 19:50:39
[群签到]请使用手机QQ进行查看。
Vincent(1733990589) 19:50:41
[群签到]请使用手机QQ进行查看。
Alex_朱江(3267538908) 19:51:07
[群签到]请使用手机QQ进行查看。
刘玎倩<lauralau20a@gmail.com> 19:52:18
[群签到]请使用手机QQ进行查看。
刘玎倩<lauralau20a@gmail.com> 19:52:19
[群签到]请使用手机QQ进行查看。
助教-杨晶(1542504647) 19:53:21
1234567(410339758) 19:58:01
[群签到]请使用手机QQ进行查看。
宋晗夫(624842732) 20:00:44
[群签到]请使用手机QQ进行查看。
姚杨兆(63220066) 20:04:38
[群签到]请使用手机QQ进行查看。
杨云峰(362464811) 20:07:51
[群签到]请使用手机QQ进行查看。
助教-林镇<andy_linky@qq.com> 20:09:28
@全体成员  没有问题，没人提问，好奇怪。
易龙(16203670) 20:09:41
我来了
易龙(16203670) 20:09:54
现在做的很郁闷啊。
助教-林镇<andy_linky@qq.com> 20:10:20
什么情况
助教-林镇<andy_linky@qq.com> 20:10:27
要开心！
易龙(16203670) 20:10:38
现在一直想用beautiful soup弄熟悉
易龙(16203670) 20:10:52
可是在beautifulSoup选择需要东西的时候
易龙(16203670) 20:10:58
就是不知道该怎么选的中。
易龙(16203670) 20:11:39
比如例子里面的。
易龙(16203670) 20:11:50
find_all('a','linkto')
易龙(16203670) 20:12:03
a代表超链接的a标签
易龙(16203670) 20:12:09
linkto代表什么呢。
赵百轶(932925940) 20:13:52
属性值

易龙(16203670) 20:13:52

易龙(16203670) 20:13:56
这儿是class。
易龙(16203670) 20:14:04
属性值，是任意属性都可以吗？
易龙(16203670) 20:14:22
比如，我能不能写'_blank'呢？
易龙(16203670) 20:14:32
我试过好像不行。
易龙(16203670) 20:15:25
比如我像定位到<div class="text">中间的url<div>
易龙(16203670) 20:15:43
我能不能迭代呢，代码该怎么写呢？
易龙(16203670) 20:16:07

易龙(16203670) 20:16:59
find_all的时候可以像xpath这样层级的往下找吗？
我只找class='Q-tpWrap'下的 class是linkto的 超级链接
易龙(16203670) 20:17:05
beautifulSoup怎么写呢？
张晨晖(1377823574) 20:18:03
[群签到]请使用手机QQ进行查看。
赵百轶(932925940) 20:18:06
这些功能也正在尝试，请助教解答
陶徵(2037840469) 20:19:12
[群签到]请使用手机QQ进行查看。
易龙(16203670) 20:19:28
还有，抓了一批超链，中间夹杂了一个不一样的超级链接。是不是必须使用正则。可以排除某一个链接吗？

易龙(16203670) 20:21:02
我想删除string的第一行，有什么好方法吗？
助教-林镇<andy_linky@qq.com> 20:21:59
find_all('a','linkto') 感觉 等于 xpath 中的 xpath('//a[@class="linkto"]')
易龙(16203670) 20:23:05
就是a标签中，样式是linkto的。
助教-林镇<andy_linky@qq.com> 20:25:00
@易龙 

助教-林镇<andy_linky@qq.com> 20:25:10
可以试试这个写法啊
易龙(16203670) 20:25:56
我写过，只要是属性值。都可以这样attr+dict的写法
易龙(16203670) 20:26:06
这种还是不错。
易龙(16203670) 20:26:43
只是我想用find_all找子项目，可以实现吗？
易龙(16203670) 20:27:48
比如，我想找这个p的内容。
易龙(16203670) 20:28:05
div下面的第六个p
易龙(16203670) 20:28:38
找div的写法很多。都没有问题，id，class，都行。
助教-林镇<andy_linky@qq.com> 20:28:51
那就可以了撒。
助教-林镇<andy_linky@qq.com> 20:29:00
如果你找到了 div 那一层。
易龙(16203670) 20:29:07
这他下面的第6<p>呢。
助教-林镇<andy_linky@qq.com> 20:29:43
soup.find_all('p')[5]
助教-林镇<andy_linky@qq.com> 20:29:47
是不是这样啊
易龙(16203670) 20:30:27
我可以对找到的soup = find_all()
易龙(16203670) 20:30:38
我可以对这个soup继续用find_all吗？
易龙(16203670) 20:30:56
就像你写的那样？
易龙(16203670) 20:31:57
content = soup.find_all()
然后我可以对ariticle = content.find_all()
易龙(16203670) 20:32:04
可以用这种写法吗？
易龙(16203670) 20:32:09
我自己试试
易龙(16203670) 20:33:27
好像不行啊，报错了。
助教-林镇<andy_linky@qq.com> 20:35:43
啥错啊
易龙(16203670) 20:37:27
    "ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'find'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?
易龙(16203670) 20:37:58
soup = BeautifulSoup(html, from_encoding='gb2312')
title = soup.title
soup2 = soup.find_all(id="Cnt-Main-Article-QQ")
content = soup2.find('p')
易龙(16203670) 20:38:03
我是这样写的。
助教-林镇<andy_linky@qq.com> 20:39:05
soup2 先看看这个对象是什么内容啊
杨亚强(782506796) 20:39:43
为什么云平台不能下载文件了？
易龙(16203670) 20:39:47
我看到了，这个是个list类型。
易龙(16203670) 20:40:15
我试试加上[0]
助教-林镇<andy_linky@qq.com> 20:40:51
@杨亚强 
哪里，你怎么操作的。
杨亚强(782506796) 20:41:15

杨亚强(782506796) 20:41:40
我下载了一个图片，想下载下来，但是没有download选项了
助教-林镇<andy_linky@qq.com> 20:43:42
jpg
助教-林镇<andy_linky@qq.com> 20:43:50
你打开它
助教-林镇<andy_linky@qq.com> 20:43:52
行不？
杨亚强(782506796) 20:43:56
不能下载？
易龙(16203670) 20:44:17
@助教-林镇 好了，可以再次find_all。大赞双击查看原图
易龙(16203670) 20:44:24
看来还是要多学习啊。。。。
杨亚强(782506796) 20:44:30
其他的文件也是一样，没有下载选项
杨亚强(782506796) 20:44:39

易龙(16203670) 20:45:05

助教-林镇<andy_linky@qq.com> 20:45:06

助教-林镇<andy_linky@qq.com> 20:45:11
直接打开啊。
助教-林镇<andy_linky@qq.com> 20:45:14
可以点开

	2017-07-18	
杨亚强(782506796) 20:45:19
是可以打开
姚杨兆(63220066) 20:45:25
我刚刚补上了第一课最后一题没来得及做的作业╮(╯▽╰)╭
助教-林镇<andy_linky@qq.com> 20:45:30
@易龙 双击查看原图
杨亚强(782506796) 20:45:42
就是为啥突然不能下载了双击查看原图
20:45:58
你撤回了一条消息
助教-林镇<andy_linky@qq.com> 20:46:13
那你应该知道如何下载了啊！
杨亚强(782506796) 20:47:20

杨亚强(782506796) 20:47:36
说明文件里面的Download选项没有了
杨亚强(782506796) 20:47:56

杨亚强(782506796) 20:48:20
没有Download选项该怎么下载？
助教-林镇<andy_linky@qq.com> 20:48:39
这个是要打开文件后。
助教-林镇<andy_linky@qq.com> 20:48:45
菜单中有download
20:49:29
你撤回了一条消息
助教-林镇<andy_linky@qq.com> 20:49:34
类似这样的
助教-林镇<andy_linky@qq.com> 20:49:54
唉我去
助教-林镇<andy_linky@qq.com> 20:50:00
这不对。
杨亚强(782506796) 20:50:17
双击查看原图
杨亚强(782506796) 20:51:34
林大侠还是向后台反应一下吧
助教-林镇<andy_linky@qq.com> 20:52:00
@杨亚强 打包后下载。
助教-林镇<andy_linky@qq.com> 20:52:15
你找找 zip 用法 
助教-林镇<andy_linky@qq.com> 20:52:24
把你要 下载的文件 zip 后。
杨亚强(782506796) 20:52:41

杨亚强(782506796) 20:52:54
打包后也没有Download选项
助教-林镇<andy_linky@qq.com> 20:52:55
直接 点呗
助教-林镇<andy_linky@qq.com> 20:53:05
为何一定要 Download选项
助教-林镇<andy_linky@qq.com> 20:53:20
没它 就不能走路了嘛
助教-林镇<andy_linky@qq.com> 20:53:22
双击查看原图
杨亚强(782506796) 20:53:24
那怎么下载？
杨亚强(782506796) 20:53:41
我要把平台上的文件下载到本地
助教-林镇<andy_linky@qq.com> 20:54:02
你点它啊。
助教-林镇<andy_linky@qq.com> 20:54:09
它是个链接是不是？
助教-林镇<andy_linky@qq.com> 20:54:24

助教-林镇<andy_linky@qq.com> 20:54:33
你的鼠标放上面，
杨亚强(782506796) 20:54:37
懂啦
助教-林镇<andy_linky@qq.com> 20:54:39
有没有变成手一样。
助教-林镇<andy_linky@qq.com> 20:54:43
双击查看原图
助教-林镇<andy_linky@qq.com> 20:54:46
我快不行了。
杨亚强(782506796) 20:54:59
默认下载了，搞得这么复杂，还必须zip一下.....
杨亚强(782506796) 20:56:00
林大侠，再咨询你一个小问题
杨亚强(782506796) 20:56:01

杨亚强(782506796) 20:56:13

杨亚强(782506796) 20:57:09
这个img_list为什么不能直接find('img',{'class':'BDE_Image'})?
助教-林镇<andy_linky@qq.com> 20:58:20
我还想问你呢。
助教-林镇<andy_linky@qq.com> 20:58:28
它报错么。
杨亚强(782506796) 20:59:32
可以啊
杨亚强(782506796) 21:00:03
这里面为啥把这个简单的指令搞得这么复杂双击查看原图
杨亚强(782506796) 21:00:19

杨亚强(782506796) 21:00:21
一模一样
[̅V̲̅I̲̅P̅]文心(25508281) 21:00:44
[群签到]请使用手机QQ进行查看。
滕生强(837301509) 21:01:38
[群签到]请使用手机QQ进行查看。
助教-林镇<andy_linky@qq.com> 21:02:22
@杨亚强 
哪里简单，哪里复杂了。
杨亚强(782506796) 21:02:40
双击查看原图
助教-林镇<andy_linky@qq.com> 21:02:47
选择你合适的就好啦，这个库本来就很多取法啊。
助教-林镇<andy_linky@qq.com> 21:03:42
@杨亚强 你只看到点，实际的应用是个面啊。
杨亚强(782506796) 21:04:05
是有很多很多种取法....
助教-林镇<andy_linky@qq.com> 21:04:18
看需要啦。
杨亚强(782506796) 21:04:25
但是每种取法都有优缺点，需要注意的问题
助教-林镇<andy_linky@qq.com> 21:04:39
看场景啦
杨亚强(782506796) 21:04:43
老师的课件既然这样写了，肯定也是有原因的
杨亚强(782506796) 21:05:31
这道题既然用这种方法，有可能也是考虑了什么因素

助教-林镇<andy_linky@qq.com> 21:05:34
你这样 的写法 soup.find(id="link3")
助教-林镇<andy_linky@qq.com> 21:05:43
只取唯一元素【节点】
助教-林镇<andy_linky@qq.com> 21:05:56
使用id时适用啦。
助教-林镇<andy_linky@qq.com> 21:06:16
那个复杂写法是取了上级的 节点 [父节点]
助教-林镇<andy_linky@qq.com> 21:06:30
然后用  find_all 取子节点啊。
助教-林镇<andy_linky@qq.com> 21:06:40
这个可能是子节点有多个的情况使用啊
杨亚强(782506796) 21:10:30
好的，谢谢
易龙(16203670) 21:10:58
content = soup2[0].find_all('p', attrs={"style": "class: text"})
易龙(16203670) 21:12:11

易龙(16203670) 21:12:50
找了好多不要的源码，中间这些没用的不应该被找出来啊。请问怎么调整呢？
[̅V̲̅I̲̅P̅]文心(25508281) 21:13:11
视频，远程桌面链接没法看么？
易龙(16203670) 21:13:37
@[̅V̲̅I̲̅P̅]文心 你说昨天晚上视频？
[̅V̲̅I̲̅P̅]文心(25508281) 21:13:55
第一课的，
易龙(16203670) 21:14:17
我之前看过，帮你瞄眼
易龙(16203670) 21:14:38
正常的
助教-林镇<andy_linky@qq.com> 21:14:44
@[̅V̲̅I̲̅P̅]文心 应该是不行吧，
陶徵(2037840469) 21:14:52
是不是不能加速
[̅V̲̅I̲̅P̅]文心(25508281) 21:14:57
我今天下午在单位看视频，整理思维导图，没弄完，我就没关机走了，现在想利用远程桌面接着看，把思维导图整理完，但发现进行不了了
易龙(16203670) 21:14:58

[̅V̲̅I̲̅P̅]文心(25508281) 21:15:00

助教-林镇<andy_linky@qq.com> 21:15:03
远程桌面后的那个 分辨率 什么的。
[̅V̲̅I̲̅P̅]文心(25508281) 21:15:20
@易龙 你这个是远程桌面？
易龙(16203670) 21:15:37
我不知道远程桌面是什么意思？
助教-林镇<andy_linky@qq.com> 21:15:45
双击查看原图
[̅V̲̅I̲̅P̅]文心(25508281) 21:15:47
好吧
易龙(16203670) 21:16:05

易龙(16203670) 21:16:08
我点的这个
易龙(16203670) 21:16:12
然后就可以看视频了。
[̅V̲̅I̲̅P̅]文心(25508281) 21:16:22
嗯嗯
助教-林镇<andy_linky@qq.com> 21:16:27
@易龙 
soup2 是什么呀？
易龙(16203670) 21:16:56
就是之前找出来的
易龙(16203670) 21:16:57
html = get_html(url)
    soup = BeautifulSoup(html, from_encoding='gb2312')
    title = soup.title
    soup2 = soup.find_all(id="Cnt-Main-Article-QQ")
    content = soup2[0].find_all('p', attrs={"style": "class: text"})
易龙(16203670) 21:17:09
之前找出来的新闻的内容。
易龙(16203670) 21:17:39
http://ent.qq.com/a/20170718/004173.htm
助教-林镇<andy_linky@qq.com> 21:17:44
你先打印一下 soup2 内容  
助教-林镇<andy_linky@qq.com> 21:17:50
print soup2.string
易龙(16203670) 21:17:51
好
助教-林镇<andy_linky@qq.com> 21:18:50
不，应该是直接  print  soup2
易龙(16203670) 21:19:20

易龙(16203670) 21:19:30

助教-林镇<andy_linky@qq.com> 21:21:36
<div bosszone="content" class="Cnt-Main-Article-QQ" id="Cnt-Main-Article-QQ">
助教-林镇<andy_linky@qq.com> 21:21:43
你取到的是这个节点撒。
易龙(16203670) 21:21:51
是的。
助教-林镇<andy_linky@qq.com> 21:23:17

助教-林镇<andy_linky@qq.com> 21:24:04


助教-林镇<andy_linky@qq.com> 21:24:50
那么 你应该这样写吧 ： content = soup2[0].find_all('p', 'text'})
易龙(16203670) 21:24:50
我可以用find_all('p','text')
助教-林镇<andy_linky@qq.com> 21:24:55
对啊
助教-林镇<andy_linky@qq.com> 21:25:01
试试。
易龙(16203670) 21:25:47
不对的。
易龙(16203670) 21:25:51
我试过了哈。
易龙(16203670) 21:26:07
找出来的就是发出来的第一个文件。
易龙(16203670) 21:26:58
文字都可以找出来。只是中间还有一段JavaScript写的貌似是视频一样的熊茜。
易龙(16203670) 21:26:59
东西
易龙(16203670) 21:28:34

易龙(16203670) 21:29:04
基本上列表中所有的网页都正常。
易龙(16203670) 21:29:39
就是这个页面不正常，这些页面都有视频。
陶徵(2037840469) 21:36:24

陶徵(2037840469) 21:36:46

陶徵(2037840469) 21:37:04
为啥搜出来的东西不完整

2017-07-18	
助教-林镇<andy_linky@qq.com> 21:37:55
@易龙 搞定没有啦。
助教-林镇<andy_linky@qq.com> 21:38:26

助教-林镇<andy_linky@qq.com> 21:39:19
@陶徵 有带id属性的是全文唯一的，你试试 soup.find(id='navigator')
助教-林镇<andy_linky@qq.com> 21:39:55
不是  soup.find('div', id='navigator')
助教-林镇<andy_linky@qq.com> 21:40:00
这样的！
陶徵(2037840469) 21:45:25

陶徵(2037840469) 21:45:29
搞懂了
陶徵(2037840469) 21:45:54
是前端基础太差的原因。。。
陶徵(2037840469) 21:46:14
这才是id=navigator的那个div...
陶徵(2037840469) 21:46:25
脚本没搜错
易龙(16203670) 21:47:24
@助教-林镇 刚刚有事儿，忙了以下
易龙(16203670) 21:47:26
一下
易龙(16203670) 21:47:56
没有搞定的嘛。用样式text，选了有多的东西
易龙(16203670) 21:49:53

助教-林镇<andy_linky@qq.com> 21:50:18

易龙(16203670) 21:50:22
也不是p标签，也没有class = "text"属性
助教-林镇<andy_linky@qq.com> 21:50:23
@易龙 
易龙(16203670) 21:50:57
我也这样写过。一样的情况双击查看原图
助教-林镇<andy_linky@qq.com> 21:51:18
我已经运行过了，结果在下面
助教-林镇<andy_linky@qq.com> 21:51:24
你说的什么情况，跟我的一样的？
助教-林镇<andy_linky@qq.com> 21:51:27
那就对了呀。。
助教-林镇<andy_linky@qq.com> 21:51:31
双击查看原图
易龙(16203670) 21:52:20

易龙(16203670) 21:52:38
把iframe都选出来了。
易龙(16203670) 21:52:55
我到网站上跑一下。
易龙(16203670) 21:53:31
网站上是对的。。。。。。
易龙(16203670) 21:53:37
晕死~！！！
易龙(16203670) 21:53:56
这时什么情况呢？@助教-林镇 
助教-林镇<andy_linky@qq.com> 21:54:11
你全部代码贴来。
助教-林镇<andy_linky@qq.com> 21:54:14
哼！
助教-林镇<andy_linky@qq.com> 21:54:29
小样，藏一半做什么啦
易龙(16203670) 21:54:48
天，不是藏一半，冤枉啊。
助教-林镇<andy_linky@qq.com> 21:55:05

助教-林镇<andy_linky@qq.com> 21:55:09
上面呢
易龙(16203670) 21:55:16

import requests
from bs4 import BeautifulSoup
import time
import re


def get_html(url):
    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}
    result = requests.get(url, headers=headers, timeout=1)
    #print result.encoding
    #print result.status_code
    return result.content

def get_urls(html):
    soup = BeautifulSoup(html)
    urls = soup.find_all('a','linkto')
    for url in urls:
        print url
    return urls

def get_content(url):
    html = get_html(url)
    soup = BeautifulSoup(html, from_encoding='gb2312')
    title = soup.title
    soup2 = soup.find_all(id="Cnt-Main-Article-QQ")
    #print soup2
    content = soup2[0].find_all('p', attrs={'class': 'text'})
    # content = soup2[0].find_all('p', 'text')
    print title.text[:-7]
    for t in content[4:]:
        print t
    print ('############################')
    time.sleep(3)

#url = 'http://ent.qq.com/star/'
#html = get_html(url)
#urls = get_urls(html)
#for url in urls:
#    get_content(url.get('href'))
get_content('http://ent.qq.com/a/20170718/004173.htm')


import requests
from bs4 import BeautifulSoup
import time
import re


def get_html(url):
    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'}
    result = requests.get(url, headers=headers, timeout=1)
    #print result.encoding
    #print result.status_code
    return result.content

def get_urls(html):
    soup = BeautifulSoup(html)
    urls = soup.find_all('a','linkto')
    for url in urls:
        print url
    return urls

def get_content(url):
    html = get_html(url)
    soup = BeautifulSoup(html, from_encoding='gb2312')
    title = soup.title
    soup2 = soup.find_all(id="Cnt-Main-Article-QQ")
    #print soup2
    #content = soup2[0].find_all('p', attrs={'class': 'text'})
    content = soup2[0].find_all('p', 'text')
    print title.text[:-7]
    for t in content[4:]:
        print t
    print ('############################')
    time.sleep(3)

#url = 'http://ent.qq.com/star/'
#html = get_html(url)
#urls = get_urls(html)
#for url in urls:
#    get_content(url.get('href'))
get_content('http://ent.qq.com/a/20170718/004173.htm')
易龙(16203670) 21:56:10
复制了两遍。
易龙(16203670) 21:56:25
同样代码，在网站上运行正常。在我本地pycharm环境里面不正常。。。
易龙(16203670) 21:56:29
林老师，怎么的呢？
助教-林镇<andy_linky@qq.com> 21:59:19

助教-林镇<andy_linky@qq.com> 21:59:24
你本地什么情况。
助教-林镇<andy_linky@qq.com> 21:59:59
可能跟环境有关啦。
助教-林镇<andy_linky@qq.com> 22:00:01
这样说的话。
助教-林镇<andy_linky@qq.com> 22:00:10
@易龙 环境不一样啦
易龙(16203670) 22:00:19
本地运行的时候中间抓了很多东西出来。
易龙(16203670) 22:00:29

易龙(16203670) 22:00:38
多了一些，向iframe都抓出来了。
助教-林镇<andy_linky@qq.com> 22:00:50
是这样的。
助教-林镇<andy_linky@qq.com> 22:00:57
articles[0].find_all('p', 'text')
易龙(16203670) 22:00:59
看来出错，要躲在线上测试了。
易龙(16203670) 22:01:12
嗯。那就ok了。
易龙(16203670) 22:01:17
能不能解释一下最后一个问题。
北京 - 柳振良(365696003) 22:01:31
[群签到]请使用手机QQ进行查看。
助教-林镇<andy_linky@qq.com> 22:01:35
这句是说 把所有 articles[0] 下的子节点中 ，p节点，class属性中包含 'text'
易龙(16203670) 22:02:02
嗯。知道了。
易龙(16203670) 22:02:03
from bs4 import BeautifulSoup
和
import BeautifulSoup
的区别呢？
易龙(16203670) 22:02:26
bs4框架的 BeautifulSoup？
bs第四版？
易龙(16203670) 22:02:52
我看文档里面好多都是这样写的from .... import ...
助教-林镇<andy_linky@qq.com> 22:03:19
对！
助教-林镇<andy_linky@qq.com> 22:03:28
Beautiful Soup 4 = bs4
陶徵(2037840469) 22:03:35
soup.find_all(href = re.compile("elsie"),id='link1')

陶徵(2037840469) 22:03:53
昨天问寒老师没理
陶徵(2037840469) 22:04:17
re.compile返回的对象是个pattern
陶徵(2037840469) 22:04:51
为啥可以直接当做attr里的东西
助教-林镇<andy_linky@qq.com> 22:05:33

助教-林镇<andy_linky@qq.com> 22:05:36
https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#find-all
助教-林镇<andy_linky@qq.com> 22:05:55
看看文档，刚好有介绍
陶徵(2037840469) 22:06:08
嗯 我看见的 soup.find_all(href = re.compile("elsie"),id='link1')  这是昨天老师给的github上的例子
陶徵(2037840469) 22:06:41
我是想知道为啥可以这样写
陶徵(2037840469) 22:07:25
pattern不是还需要调用什么match啊searc啊findall等方法才可以匹配的吗
助教-林镇<andy_linky@qq.com> 22:09:08
不是，你认为，为什么不可以这么写呢
助教-林镇<andy_linky@qq.com> 22:09:22
你认为这个函数，不能用这个做为参数么？
助教-林镇<andy_linky@qq.com> 22:10:21
@陶徵 你说的调用，可以在函数内部完成了哈。。
陶徵(2037840469) 22:10:23
因为看见各种attribute后面都跟的是字符串
助教-林镇<andy_linky@qq.com> 22:10:29
然后返回你最终要的结果。
助教-林镇<andy_linky@qq.com> 22:10:36
你可以去看源码啊。
陶徵(2037840469) 22:10:50
我。。。我看得懂么。。
助教-林镇<andy_linky@qq.com> 22:11:32
有什么不懂。
助教-林镇<andy_linky@qq.com> 22:11:35
python开源的。
助教-林镇<andy_linky@qq.com> 22:11:43
不要低估了你自己的能力。。
陶徵(2037840469) 22:22:32
@andy 
陶徵(2037840469) 22:22:35

陶徵(2037840469) 22:22:52
好像不能使用crtl f 来搜
陶徵(2037840469) 22:23:30
请问github怎么搜索某个关键字
助教-林镇<andy_linky@qq.com> 22:27:23
浏览器，的功能吧。
助教-林镇<andy_linky@qq.com> 22:27:25
这个 。。。
助教-林镇<andy_linky@qq.com> 22:27:59
https://www.crummy.com/software/BeautifulSoup/bs4/download/4.6/
陶徵(2037840469) 22:29:08
好的。。
陶徵(2037840469) 22:29:30
我正在把这个github的url变成一个soup
陶徵(2037840469) 22:30:00
然后想用find text来找 find_all
陶徵(2037840469) 22:30:10
会不会异想天开了。。
易龙(16203670) 22:40:30
不会，很好想法。
易龙(16203670) 22:40:33
加油
陶徵(2037840469) 22:49:14
谢谢！
北京 姜语桐(435062975) 23:01:13
[群签到]请使用手机QQ进行查看。
	2017-07-19	
北京 - 柳振良(365696003) 0:02:04
haha,比我签到还晚
北京 姜语桐(435062975) 0:20:51
今天 写结课论文。。忙忘记了双击查看原图
宋晗夫(624842732) 0:49:01
双击查看原图总算写好第一题了。。
Alex_朱江(3267538908) 11:28:35
@助教-杨晶 请问如何将自己的ipynb文件，去掉网页代码，导出成py或者txt格式以便保存？
助教-杨晶(1542504647) 11:32:19
@Alex_朱江 你是在自己电脑上运行的吗？
助教-杨晶(1542504647) 11:35:24

助教-杨晶(1542504647) 11:35:43
在本地是可以另存为.py文件的
Alex_朱江(3267538908) 11:38:57
ok
Alex_朱江(3267538908) 11:39:02
谢谢
Alex_朱江(3267538908) 11:39:35
提交作业不需要点击“发布”吧？
Alex_朱江(3267538908) 11:39:39
@助教-杨晶 
Alex_朱江(3267538908) 11:40:25
上次确认过，就是放在文件夹里面就好
助教-杨晶(1542504647) 11:40:25
@Alex_朱江 需要点击“发布”的
11:40:33
你邀请3期-颜晋南加入了本群。
Alex_朱江(3267538908) 11:40:46
@助教-杨晶 上次作业没有点击
助教-林镇<andy_linky@qq.com> 11:41:02
欢迎新同学~~~
助教-杨晶(1542504647) 11:41:29
@Alex_朱江 前段时间时间平台功能升级了，后续作业需要采用“发布”功能
Alex_朱江(3267538908) 11:41:42
@助教-杨晶 是在周一课开始之前提交的
颜晋南(275046686) 11:41:43
大家好，以后多多指教
助教-林镇<andy_linky@qq.com> 11:41:50
@风雪飘 有空请关注一下大群中的群文件，群公告内容。
颜晋南(275046686) 11:42:12
OK，这个周末前争取跟上进度
助教-杨晶(1542504647) 11:46:34
@Alex_朱江 Ok，暂时就按照之前的方法吧，后续会有详细通知的
北京 姜语桐(435062975) 11:48:12
@助教-杨晶 上次的作业 我也没有点击发布。。
助教-杨晶(1542504647) 11:49:08
@北京 姜语桐 暂时没有问题的
北京 姜语桐(435062975) 11:56:09
好的 谢谢～
宋晗夫(624842732) 12:49:13
怎么发布呢